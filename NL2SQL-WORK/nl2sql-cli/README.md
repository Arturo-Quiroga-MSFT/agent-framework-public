# ğŸ¯ NL2SQL Pipeline - CLI Version (No DevUI)

> **A CLI-only version** of the production-ready NL2SQL workflow that runs from command line without web interface.

## Quick Start

```bash
# Run a query
python nl2sql_workflow.py "What are the top 10 customers by revenue?"

# With session support for follow-ups
python nl2sql_workflow.py "Show me customers" session1
python nl2sql_workflow.py "What about their revenue?" session1
```

## Configuration

Copy `.env` from parent directory or configure:
- `AZURE_OPENAI_ENDPOINT`
- `AZURE_OPENAI_DEPLOYMENT_NAME`
- MSSQL connection details

## Key Differences from DevUI Version

âœ… No web server - faster startup  
âœ… CLI arguments - direct execution  
âœ… Same pipeline logic & executors  
âœ… Same output files & exports  
âŒ No web UI  
âŒ No REST API endpoint

---

# Original Documentation Below

---

## ğŸš€ Quick Start

```bash
# 1. Configure environment
cp .env.example .env
# Edit .env with your Azure OpenAI and SQL Database credentials

# 2. Launch the pipeline
python nl2sql_workflow.py

# 3. Open DevUI
open http://localhost:8097
```

**That's it!** Ask questions in natural language and get SQL-powered answers with automatic visualizations.

### Try These Example Questions

```
"What are the top 10 customers by revenue?"
"Show me monthly sales trends for 2024"
"Which products are currently out of stock?"
"Compare revenue across different regions"
```

---

## âœ¨ Key Features

### ğŸ—£ï¸ Natural Language Interface
Ask questions in plain English - no SQL knowledge required. The LLM understands context, intent, and business terminology.

### ğŸ§  Intelligent SQL Generation
- **Automatic schema discovery** - No manual configuration needed
- **Context-aware queries** - Understands table relationships and joins
- **Error recovery** - Automatically fixes and retries failed queries
- **Query optimization** - Adds appropriate limits and indexes

### ğŸ›¡ï¸ Enterprise-Grade Safety
âœ… SQL injection prevention (parameterized queries)  
âœ… Dangerous operation blocking (DROP, DELETE, ALTER)  
âœ… Row limit enforcement (prevents large exports)  
âœ… Read-only mode by default  
âœ… Query validation and syntax checking  
âœ… Schema isolation (optional restrictions)  

### ğŸ“Š Automatic Data Export & Visualization
- **CSV & Excel export** with timestamps for every query
- **Smart chart generation** - Automatically selects appropriate chart type
- **Multiple formats** - Horizontal bar charts, line charts, pie charts, heatmaps
- **Professional styling** - Publication-ready visualizations
- **Organized output** - Separate `exports/` and `visualizations/` directories

### âš¡ High Performance
- **Schema caching** - 100-500x faster with intelligent caching
  - First query: ~500ms for schema retrieval
  - Subsequent queries: <1ms (cached)
- **Memory + file cache** - Survives workflow restarts
- **Auto-refresh** - Cache updates every 5 minutes
- **Total end-to-end**: 3-10 seconds per query

### ğŸ” Full Observability
- Real-time trace viewing in DevUI
- OpenTelemetry support (OTLP endpoints)
- Application Insights integration
- Console logging with configurable levels
- Complete pipeline step tracking

---

## ğŸ—ï¸ Architecture

**Pattern**: Sequential Pipeline combining LLM Agents + Custom Executors

```
User Question (Natural Language)
    â†“
[1] Input Normalizer (Executor)
    â†“ Parse & structure input
    â†“
[2] Schema Retriever (Executor) â”€â”€â†’ Azure SQL Database
    â†“ [Schema cached for 100-500x speedup]
    â†“
[3] SQL Generator Agent (LLM) â”€â”€â†’ Azure OpenAI GPT-4
    â†“ Generate SQL from question + schema
    â†“
[4] SQL Validator (Executor)
    â†“ Safety checks & optimization
    â†“
[5] Query Executor (Executor) â”€â”€â†’ Azure SQL Database
    â†“ Execute validated query
    â†“
[6] Results Interpreter Agent (LLM) â”€â”€â†’ Azure OpenAI GPT-4
    â†“ Natural language insights
    â†“
[7] Data Exporter (Executor) â”€â”€â†’ CSV & Excel Files
    â†“ Timestamped exports
    â†“
[8] Visualization Generator (Executor) â”€â”€â†’ PNG Charts
    â†“ Smart chart selection & rendering
    â†“
Natural Language Answer + Insights + Data Files + Charts
```

### Components

| Component | Type | Purpose |
|-----------|------|---------|
| Input Normalizer | Executor | Parse and validate user input |
| Schema Retriever | Executor | Fetch database schema (with caching) |
| SQL Generator | Agent (LLM) | Generate SQL from natural language |
| SQL Validator | Executor | Safety checks and query optimization |
| Query Executor | Executor | Execute SQL against database |
| Results Interpreter | Agent (LLM) | Convert results to natural language |
| Data Exporter | Executor | Export to CSV and Excel |
| Visualization Generator | Executor | Create appropriate charts |

**[â†’ View detailed architecture documentation](docs/reference/ARCHITECTURE.md)**

---

## ğŸ“‹ Prerequisites

### Required Services
- **Azure OpenAI** - GPT-4 or GPT-4 Turbo deployment
- **Azure SQL Database** - Accessible database with read permissions
- **Python 3.10+** - With agent framework installed

### Authentication
```bash
# Login to Azure
az login

# Verify access to Azure OpenAI
az cognitiveservices account show --name <your-openai-resource>

# Verify access to Azure SQL
sqlcmd -S <your-server>.database.windows.net -d <your-database> -U <username>
```

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the `nl2sql-pipeline/` directory:

```bash
# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# Azure SQL Database Configuration
MSSQL_SERVER_NAME=your-server.database.windows.net
MSSQL_DATABASE_NAME=your-database
MSSQL_CONNECTION_ID=<obtained-from-mssql-connect>

# Optional: Schema Caching (default: enabled)
ENABLE_SCHEMA_CACHE=true
SCHEMA_CACHE_TTL=300  # 5 minutes

# Optional: Query Safety (default: read-only)
ALLOW_WRITE_OPERATIONS=false
MAX_RESULT_ROWS=1000

# Optional: Tracing/Observability
ENABLE_CONSOLE_TRACING=true
# OR
OTLP_ENDPOINT=http://localhost:4317
# OR
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=...
```

**[â†’ View complete configuration reference](docs/reference/CONFIGURATION.md)**

---

## ğŸ“– Documentation

### ğŸš€ Getting Started
- **[Quick Start Guide](docs/guides/QUICKSTART.md)** - Get running in 5 minutes
- **[Database Setup](docs/guides/DATABASE_SETUP.md)** - Configure Azure SQL Database
- **[Testing Guide](docs/guides/TESTING_GUIDE.md)** - Run tests and validate setup

### ğŸ“š Feature Guides
- **[Schema Caching Guide](docs/guides/SCHEMA_CACHE_GUIDE.md)** - 100-500x performance improvement
- **[Visualization Guide](docs/guides/VISUALIZATION_GUIDE.md)** - Automatic chart generation
- **[Export Guide](docs/guides/EXPORT_GUIDE.md)** - CSV and Excel data export

### ğŸ”§ Reference
- **[Architecture Documentation](docs/reference/ARCHITECTURE.md)** - System design and data flow
- **[Configuration Reference](docs/reference/CONFIGURATION.md)** - All settings explained
- **[INDEX](INDEX.md)** - Complete file and artifact index

---

## ğŸ’¡ Usage Examples

### Basic Queries
```
"Show me all customers from California"
"List all products with price greater than $100"
"What orders were placed in the last 7 days?"
```

### Analytics & Aggregations
```
"What are the top 10 customers by revenue?" â†’ Bar chart
"Show me monthly sales for 2024" â†’ Line chart
"Sales breakdown by category" â†’ Pie chart
"Which regions have the highest order volume?" â†’ Bar chart
```

### Trends & Time Series
```
"Show me daily sales for the past 30 days" â†’ Line chart
"What's the revenue trend by quarter?" â†’ Line chart
"How has customer growth changed over time?" â†’ Line chart
```

### Complex Queries
```
"Compare year-over-year sales growth by product category"
"Show me customer lifetime value distribution by segment"
"Which sales representatives have the best conversion rates?"
```

---

## ğŸ“Š Output Files

### Automatic Exports

Every query generates three types of output:

1. **CSV Files** - `exports/query_results_YYYYMMDD_HHMMSS.csv`
   - Standard CSV format with headers
   - All data types preserved
   - Ready for Excel, Python, R analysis

2. **Excel Files** - `exports/query_results_YYYYMMDD_HHMMSS.xlsx`
   - Formatted workbook with styled headers
   - Auto-sized columns
   - Professional formatting

3. **Visualizations** - `visualizations/chart_YYYYMMDD_HHMMSS.png`
   - High-resolution PNG images (300 DPI)
   - Professional styling with seaborn
   - Appropriate chart type auto-selected

---

## ğŸ”’ Security Features

### Query Safety
- **Whitelist approach** - Only SELECT by default
- **Dangerous operation blocking** - Prevents DROP, DELETE, ALTER, TRUNCATE, EXEC
- **Row limits** - Automatic TOP/LIMIT clause enforcement
- **Parameterized queries** - SQL injection prevention
- **Schema isolation** - Optional restrictions to specific schemas

### Database Access
- **Read-only mode** - Default configuration
- **Azure AD authentication** - Secure credential-free access
- **Connection pooling** - Efficient resource usage
- **Timeout enforcement** - Prevents long-running queries

### Audit & Compliance
- **Full query logging** - All SQL queries are traced
- **User attribution** - Track who asked what
- **Result tracking** - Log all data access
- **Observability integration** - Send to SIEM/monitoring systems

---

## ğŸ› ï¸ Customization

### Modify Agent Instructions

Edit [nl2sql_workflow.py](nl2sql_workflow.py):

```python
sql_generator = client.create_agent(
    instructions="""You are an expert SQL generator for our retail database.
    
    Domain-specific rules:
    - Always use CustomerID instead of CustomerName for joins
    - Sales data is in UTC timezone
    - Revenue should be calculated as Quantity * UnitPrice
    """,
    name="sql_generator",
)
```

### Add Custom Validators

Edit [executors.py](executors.py):

```python
class SQLValidatorExecutor(Executor):
    def _check_safety(self, sql: str):
        # Add your domain-specific rules
        if "SENSITIVE_TABLE" in sql.upper():
            return False, ["Access to sensitive table denied"]
        
        # Check for required WHERE clauses
        if "FROM orders" in sql.lower() and "WHERE" not in sql.upper():
            return False, ["Orders table requires WHERE clause"]
            
        return True, []
```

### Add Pipeline Steps

Insert custom executors in [nl2sql_workflow.py](nl2sql_workflow.py):

```python
builder.participants([
    input_normalizer,
    schema_retriever,
    sql_generator,
    your_custom_optimizer,  # â† Add custom steps here
    sql_validator,
    query_executor,
    results_interpreter,
    data_exporter,
    visualization_generator,
])
```

---

## ğŸ“ˆ Performance Benchmarks

| Metric | Without Cache | With Cache | Improvement |
|--------|---------------|------------|-------------|
| Schema retrieval | 500-1000ms | 1-5ms | **100-500x** |
| SQL generation | 1-3s | 1-3s | Same (LLM) |
| Query execution | 100ms-5s | 100ms-5s | Same |
| Total pipeline | 3-12s | 2-10s | 15-40% faster |

### Optimization Tips
- Enable schema caching (default: ON)
- Use specific table names in questions
- Avoid unbounded queries (add time filters)
- Monitor query execution time in DevUI

---

## ğŸ› Troubleshooting

### Connection Issues

```bash
# Test Azure SQL connection
python test_db_connection.py

# Check MSSQL MCP tools
python -c "from db_utils import test_connection; test_connection()"
```

### SQL Generation Issues

- **Problem**: Generated SQL is incorrect
- **Solution**: Review schema context in DevUI traces, adjust agent instructions

### Query Execution Failures

- **Problem**: Query fails to execute
- **Solution**: Check database permissions, firewall rules, review SQL in validator output

### Performance Issues

- **Problem**: Queries are slow
- **Solution**: Enable schema caching, check query execution time in database, add indexes

**[â†’ View complete troubleshooting guide](docs/guides/TESTING_GUIDE.md)**

---

## ğŸš€ Deployment

### Local Development
```bash
python nl2sql_workflow.py
```

### Azure Container Instance
```bash
# Build Docker image
docker build -t nl2sql-pipeline .

# Deploy to ACI
az container create \
    --resource-group your-rg \
    --name nl2sql-pipeline \
    --image nl2sql-pipeline \
    --ports 8097 \
    --environment-variables \
        AZURE_OPENAI_ENDPOINT=$AZURE_OPENAI_ENDPOINT \
        MSSQL_SERVER_NAME=$MSSQL_SERVER_NAME
```

### Azure Functions
```bash
# Deploy as HTTP-triggered function
func azure functionapp publish your-function-app
```

---

## ğŸ¤ Contributing

### Extend This Pipeline

1. **Add new validators** - Edit [executors.py](executors.py)
2. **Add pipeline steps** - Edit [nl2sql_workflow.py](nl2sql_workflow.py)
3. **Customize agents** - Modify agent instructions
4. **Add chart types** - Extend [visualizer.py](visualizer.py)

### Testing

```bash
# Run comprehensive tests
python test_workflow.py

# Test specific components
python test_visualizations.py
python test_db_connection.py
```

---

## ğŸ“¦ Project Structure

```
nl2sql-pipeline/
â”œâ”€â”€ README.md                      # This file - main documentation
â”œâ”€â”€ INDEX.md                       # Complete file index
â”œâ”€â”€ .env                          # Your configuration (not in git)
â”œâ”€â”€ .env.example                  # Configuration template
â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚
â”œâ”€â”€ nl2sql_workflow.py            # Main workflow orchestration
â”œâ”€â”€ executors.py                  # Custom business logic executors
â”œâ”€â”€ schema_cache.py               # Schema caching implementation
â”œâ”€â”€ visualizer.py                 # Chart generation logic
â”œâ”€â”€ db_utils.py                   # Database utility functions
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ guides/                   # How-to guides
â”‚   â”‚   â”œâ”€â”€ QUICKSTART.md
â”‚   â”‚   â”œâ”€â”€ SCHEMA_CACHE_GUIDE.md
â”‚   â”‚   â”œâ”€â”€ VISUALIZATION_GUIDE.md
â”‚   â”‚   â”œâ”€â”€ EXPORT_GUIDE.md
â”‚   â”‚   â”œâ”€â”€ TESTING_GUIDE.md
â”‚   â”‚   â””â”€â”€ DATABASE_SETUP.md
â”‚   â””â”€â”€ reference/                # Technical reference
â”‚       â”œâ”€â”€ ARCHITECTURE.md
â”‚       â””â”€â”€ CONFIGURATION.md
â”‚
â”œâ”€â”€ examples/                     # Example queries and use cases
â”‚   â””â”€â”€ sample_questions.md
â”‚
â”œâ”€â”€ exports/                      # Auto-generated CSV/Excel files
â”‚   â””â”€â”€ query_results_*.{csv,xlsx}
â”‚
â”œâ”€â”€ visualizations/               # Auto-generated charts
â”‚   â””â”€â”€ chart_*.png
â”‚
â”œâ”€â”€ .cache/                       # Schema cache files (auto-generated)
â”‚   â””â”€â”€ schema_cache_*.json
â”‚
â”œâ”€â”€ archive/                      # Historical docs and test files
â”‚   â”œâ”€â”€ BUGFIX_NOTES.md
â”‚   â”œâ”€â”€ TEST_SUCCESS_SUMMARY.md
â”‚   â””â”€â”€ EXPORT_TEST.md
â”‚
â””â”€â”€ tests/                        # Test files
    â”œâ”€â”€ test_workflow.py
    â”œâ”€â”€ test_visualizations.py
    â””â”€â”€ test_db_connection.py
```

---

## ğŸ“„ License

See repository [LICENSE](../LICENSE) file.

---

## ğŸ‰ Success Indicators

You'll know the pipeline is working when:

âœ… DevUI opens at http://localhost:8097  
âœ… Schema retrieval displays your database tables  
âœ… SQL generation produces valid queries  
âœ… Queries execute and return results  
âœ… Natural language answers are generated  
âœ… CSV/Excel files appear in `exports/`  
âœ… Charts appear in `visualizations/`  
âœ… Complete traces visible in DevUI  

---

## ğŸ“ Support

### Resources
- **Agent Framework Docs** - See [python/README.md](../python/README.md)
- **Workflow Samples** - See [python/samples/](../python/samples/)
- **MSSQL MCP Tools** - See [MssqlMcp/](../MssqlMcp/)

### Common Questions
- **Q: Can I use other databases?** - Yes, modify [db_utils.py](db_utils.py) for PostgreSQL, MySQL, etc.
- **Q: Can I use other LLMs?** - Yes, agent framework supports multiple providers
- **Q: Is this production-ready?** - Yes, includes error handling, validation, and observability

---

**Created**: October 2025  
**Framework**: Microsoft Agent Framework  
**Pattern**: Sequential Pipeline with Agents + Custom Executors  
**Status**: âœ… Production Ready  
**Performance**: 3-10s end-to-end with 100-500x schema caching speedup
