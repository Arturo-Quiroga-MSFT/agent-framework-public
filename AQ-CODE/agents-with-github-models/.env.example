# ============================================================================
# GitHub Models Configuration Template
# ============================================================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control!
# ============================================================================

# ----------------------------------------------------------------------------
# REQUIRED: GitHub Authentication
# ----------------------------------------------------------------------------

# Your GitHub Personal Access Token
# Get one at: https://github.com/settings/tokens
# Scopes needed: (basic authentication - no special scopes required)
GITHUB_TOKEN=github_pat_YOUR_TOKEN_HERE

# ----------------------------------------------------------------------------
# GitHub Models Configuration
# ----------------------------------------------------------------------------

# Model to use (default: gpt-4o-mini)
# Available models:
#   - gpt-4o                      # Latest GPT-4o, best reasoning
#   - gpt-4o-mini                 # Fast, cost-effective
#   - Llama-3.3-70B-Instruct      # Meta's Llama 3.3, 128K context
#   - Llama-3.1-405B-Instruct     # Largest Llama model
#   - Llama-3.1-70B-Instruct      # Balanced Llama model
#   - Phi-4                       # Microsoft's small, efficient model
#   - Mistral-Large-2             # Mistral's largest model
#   - Mistral-Nemo                # Smaller Mistral model
GITHUB_MODEL=gpt-4.1-mini

# GitHub Models API endpoint (usually no need to change)
GITHUB_BASE_URL=https://models.inference.ai.azure.com

# ----------------------------------------------------------------------------
# Optional: Logging and Debugging
# ----------------------------------------------------------------------------

# Log level (DEBUG, INFO, WARNING, ERROR)
MAF_LOG_LEVEL=INFO

# Enable OpenTelemetry tracing (true/false)
MAF_ENABLE_TRACING=true

# ----------------------------------------------------------------------------
# Optional: For Comparison Examples (Azure OpenAI)
# ----------------------------------------------------------------------------

# If you want to run comparison examples with Azure OpenAI:
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini
# AZURE_OPENAI_API_KEY=your-key-here

# ----------------------------------------------------------------------------
# Optional: For Foundry V2 Examples (Azure AI Foundry)
# ----------------------------------------------------------------------------

# If you want to test Foundry V2 server-side agents:
# AZURE_AI_PROJECT_ENDPOINT=https://your-project.services.ai.azure.com/api/projects/your-project
# AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4o-mini

# ----------------------------------------------------------------------------
# Notes
# ----------------------------------------------------------------------------
# 
# Rate Limits (GitHub Models free tier):
#   - ~15 requests per minute
#   - ~150K tokens per minute
#   - Subject to change, check: https://docs.github.com/en/github-models
#
# For production use:
#   - Use Azure OpenAI or Azure AI Foundry instead
#   - GitHub Models is intended for development and testing
#
# Security:
#   - Never commit your .env file
#   - Add .env to .gitignore
#   - Rotate tokens regularly
#
# ============================================================================
