# LLMOps for Microsoft Agent Framework (MAF)

This directory contains LLMOps utilities and best practices for production-ready MAF agents.

## ğŸ“ Directory Structure

```
llmops/
â”œâ”€â”€ core/                           # Core LLMOps modules
â”‚   â”œâ”€â”€ observability.py           # Application Insights integration
â”‚   â”œâ”€â”€ cost_tracker.py            # Cost tracking & budget management
â”‚   â”œâ”€â”€ evaluator.py               # Response quality evaluation
â”‚   â””â”€â”€ agent_lifecycle_manager.py # Agent lifecycle management
â”œâ”€â”€ examples/                       # Example implementations
â”‚   â”œâ”€â”€ example_production_agent.py           # Basic production agent
â”‚   â”œâ”€â”€ production_agent_enhanced.py          # Enhanced with UI support
â”‚   â”œâ”€â”€ production_agent_with_lifecycle.py    # With lifecycle management
â”‚   â””â”€â”€ test_streaming.py                     # Streaming tests
â”œâ”€â”€ ui/                             # Streamlit UI components
â”‚   â”œâ”€â”€ streamlit_production_ui.py  # Full-featured UI
â”‚   â”œâ”€â”€ streamlit_simple_ui.py      # Simplified UI
â”‚   â””â”€â”€ requirements-ui.txt         # UI dependencies
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ QUICKSTART.md              # Getting started guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # System architecture
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md         # Common issues & solutions
â”‚   â”œâ”€â”€ AGENT_LIFECYCLE_MANAGEMENT.md  # Lifecycle guide
â”‚   â”œâ”€â”€ LIFECYCLE_SUMMARY.md       # Team overview
â”‚   â””â”€â”€ LIFECYCLE_QUICK_REFERENCE.md   # Quick reference
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ quickstart.sh                   # Interactive setup script
â””â”€â”€ __init__.py                     # Package exports
```

## ğŸ“‹ Documentation

### Getting Started
- **[docs/QUICKSTART.md](docs/QUICKSTART.md)** - Quick start guide with examples
- **[quickstart.sh](quickstart.sh)** - Interactive setup script

### Core Concepts
- **[docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System architecture and design
- **[docs/AGENT_LIFECYCLE_MANAGEMENT.md](docs/AGENT_LIFECYCLE_MANAGEMENT.md)** - Agent lifecycle best practices

### Best Practices
- **[../LLMOPS/MAF_LLMOPS_BEST_PRACTICES.md](../LLMOPS/MAF_LLMOPS_BEST_PRACTICES.md)** - Comprehensive guide (60+ pages)

### Help & Support
- **[docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** - Common issues and solutions
- **[docs/LIFECYCLE_QUICK_REFERENCE.md](docs/LIFECYCLE_QUICK_REFERENCE.md)** - Quick reference guide

### LLMOps Modules

All core modules are in the `core/` directory:

#### `core/agent_lifecycle_manager.py` ğŸ†•
Centralized agent lifecycle management to prevent resource proliferation:
- Agent registry with reuse capability
- Thread-safe operations with asyncio.Lock
- Usage statistics and monitoring
- Proper cleanup on shutdown
- Optional persistent registry

```python
from llmops.core.agent_lifecycle_manager import ProductionAgentManager

# Get or create agent (reuses if exists)
agent, cred, client = await ProductionAgentManager.get_or_create_agent(
    agent_name="market_analyst",
    instructions="You are a market analyst...",
    enable_web_search=True,
    session_id="session_123"
)

# Get usage statistics
stats = ProductionAgentManager.get_agent_stats()
print(f"Total agents: {stats['total_agents']}")

# Cleanup
await ProductionAgentManager.cleanup_agent("market_analyst")
await ProductionAgentManager.cleanup_all()
```

#### `core/observability.py`
Application Insights integration for MAF agents:
- Distributed tracing with OpenTelemetry
- Custom metrics (agent calls, latency, token usage)
- Span creation for detailed tracking

```python
from llmops.core.observability import MAFObservability

observability = MAFObservability()
observability.track_agent_call(
    agent_name="market_analyst",
    duration_ms=1250.5,
    tokens=850,
    success=True
)
```

#### `core/cost_tracker.py`
Cost tracking and budget management:
- Real-time cost calculation based on model pricing
- Token usage tracking per agent
- Daily budget enforcement
- Per-request token limits

```python
from llmops.core.cost_tracker import CostTracker, TokenBudgetManager

# Track costs
cost_tracker = CostTracker()
cost_tracker.record_cost(
    model="gpt-4.1",
    prompt_tokens=100,
    completion_tokens=500,
    agent_name="analyst"
)
print(f"Total cost: ${cost_tracker.get_total_cost():.4f}")

# Enforce budgets
budget_manager = TokenBudgetManager()
allowed, message = budget_manager.check_budget(estimated_tokens=800)
if allowed:
    # Proceed with request
    budget_manager.record_usage(request_id, actual_tokens)
```

#### `core/evaluator.py`
Response quality evaluation:
- Topic coverage analysis
- Citation detection
- Quantitative data presence
- Structure assessment
- Sentiment analysis
- Overall quality scoring

```python
from llmops.core.evaluator import AgentEvaluator

evaluator = AgentEvaluator()
metrics = evaluator.evaluate_response(
    response="NVIDIA's P/E ratio is 45.2 as of Q4 2025...",
    expected_topics=["P/E ratio", "NVIDIA", "valuation"]
)
print(f"Quality Score: {metrics['overall_score']:.2f}")
print(f"Quality Label: {evaluator.get_quality_label(metrics['overall_score'])}")
```

### Examples

All examples are in the `examples/` directory:

#### `examples/production_agent_with_lifecycle.py` ğŸ†•
Enhanced production agent with lifecycle management:
- Agent reuse to prevent Foundry resource proliferation
- All LLMOps integrations maintained
- Thread management for conversation continuity
- Progress callbacks for UI integration
- Backward compatible with optional `reuse_agent` flag

**Run the example:**
```bash
cd AQ-CODE/llmops
python examples/production_agent_with_lifecycle.py
```

**Key features:**
```python
from llmops.examples.production_agent_with_lifecycle import ProductionAgent

# First instance creates agent in Foundry
agent1 = ProductionAgent(
    agent_name="market_analyst",
    instructions="You are a market analyst...",
    enable_web_search=True,
    reuse_agent=True  # Enable agent reuse
)
await agent1.run("What's NVIDIA's P/E ratio?")

# Second instance reuses same agent (not created again!)
agent2 = ProductionAgent(
    agent_name="market_analyst",
    instructions="You are a market analyst...",
    enable_web_search=True,
    reuse_agent=True
)
await agent2.run("What about Microsoft?")  # Reuses agent

# Check if agent was reused
print(f"Agent reused: {result.agent_reused}")
```

#### `examples/agent_lifecycle_manager.py`
Standalone demo of agent lifecycle management:
```bash
cd AQ-CODE/llmops
python core/agent_lifecycle_manager.py
```

#### `examples/example_production_agent.py`
Complete working example demonstrating:
- Agent initialization with LLMOps integration
- Budget checking before requests
- Cost tracking with real-time calculations
- Response evaluation with metrics
- Observability tracking
- Structured output with comprehensive logging

**Run the example:**
```bash
cd AQ-CODE/llmops
python examples/example_production_agent.py
```

**Example output:**
```
================================================================================
ğŸš€ MAF Production Agent with LLMOps - Demo
================================================================================

################################################################################
# Test Query 1/2
################################################################################

================================================================================
ğŸ¤– Agent: market_analyst
ğŸ“ Query: What is NVIDIA's current P/E ratio and how does it compare to industry averages?
ğŸ†” Request ID: 3f7d8a9b-c4e2-4f8a-b5d3-1e6c9a8b2d4f
================================================================================
âœ… Budget Check: OK (estimated 525 tokens)
ğŸ”„ Running agent...
ğŸ’° Cost Tracking:
   Prompt tokens: 195
   Completion tokens: 750
   Total tokens: 945
   Estimated cost: $0.0285

ğŸ“Š Quality Evaluation:
   Overall Score: 0.82 (Excellent)
   Topic Coverage: 100%
   Has Citations: âœ…
   Has Numbers: âœ…
   Well Structured: âœ…

â±ï¸  Duration: 1245ms

ğŸ’¬ Response:
--------------------------------------------------------------------------------
Based on current market data as of November 2025, NVIDIA's P/E ratio is 
approximately 45.2, significantly above the semiconductor industry average 
of 28.5. This premium valuation reflects investor confidence in NVIDIA's 
AI chip dominance...
--------------------------------------------------------------------------------
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ Test CLI (30 seconds)

```bash
cd AQ-CODE/llmops
python examples/production_agent_with_lifecycle.py
```

### 2ï¸âƒ£ Launch UI (2 minutes)

```bash
# Install UI dependencies
pip install -r ui/requirements-ui.txt

# Launch
cd AQ-CODE/llmops
streamlit run ui/streamlit_production_ui.py
```

Opens at: `http://localhost:8501`

### 3ï¸âƒ£ Interactive Script

```bash
cd AQ-CODE/llmops
./quickstart.sh
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies
Already included in your `requirements.txt`:
- `opentelemetry-api`
- `opentelemetry-sdk`
- `azure-monitor-opentelemetry`

### 2. Configure Environment
Add to your `.env` file:

```bash
# Monitoring
APPLICATIONINSIGHTS_CONNECTION_STRING=<your-app-insights-connection>
ENABLE_TRACING=true

# Cost Controls
DAILY_TOKEN_BUDGET=1000000
MAX_TOKENS_PER_REQUEST=4000

# Model Configuration
AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4.1
```

### 3. Use in Your Agents

```python
from llmops import MAFObservability, CostTracker, TokenBudgetManager, AgentEvaluator

# Initialize LLMOps components
observability = MAFObservability()
cost_tracker = CostTracker()
budget_manager = TokenBudgetManager()
evaluator = AgentEvaluator()

# In your agent workflow
async def run_agent_with_llmops(agent, query: str):
    # Check budget
    estimated_tokens = len(query.split()) * 1.5 + 500
    allowed, msg = budget_manager.check_budget(int(estimated_tokens))
    if not allowed:
        return {"error": msg}
    
    # Run agent with tracking
    start = time.time()
    response = await agent.run(query)
    duration_ms = (time.time() - start) * 1000
    
    # Track costs
    tokens = len(response.split()) * 1.5
    cost_tracker.record_cost("gpt-4.1", 100, int(tokens), "my_agent")
    
    # Evaluate quality
    metrics = evaluator.evaluate_response(response, ["topic1", "topic2"])
    
    # Track observability
    observability.track_agent_call("my_agent", duration_ms, int(tokens), True)
    
    return {"response": response, "metrics": metrics}
```

## ğŸš€ Streamlit UI

### Launch the UI

```bash
cd AQ-CODE/llmops
streamlit run ui/streamlit_production_ui.py
```

### Features
- âœ… 3-tab interface (Chat, Analytics, History)
- âœ… Real-time cost tracking
- âœ… Interactive charts (Plotly)
- âœ… Quality score gauges
- âœ… Budget warnings
- âœ… Session download button
- âœ… Agent preset switching
- âœ… **Smart follow-up questions** ğŸ†• - AI-generated contextual suggestions after each response

### Smart Follow-Up Questions ğŸ†•

After each agent response, the system automatically generates 3 contextual follow-up questions to help users:
- Dive deeper into topics
- Explore related areas
- Continue the conversation naturally

**How it works:**
1. Agent processes your query and generates response
2. System analyzes conversation context
3. Generates 3 relevant follow-up questions
4. Click any question to use it as your next prompt

**Example:**
```
User: "What is NVIDIA's P/E ratio?"
Agent: [Provides detailed analysis with numbers and sources]

ğŸ’¡ Suggested follow-up questions:
1. How does NVIDIA's P/E ratio compare to AMD and Intel?
2. What factors are driving NVIDIA's current valuation?
3. Is NVIDIA's stock price justified by its fundamentals?
```

See **[docs/UI_README.md](docs/UI_README.md)** for complete UI documentation.

## ğŸ“Š Monitoring

### Application Insights Queries

**Agent Performance:**
```kusto
customMetrics
| where name == "maf.agent.calls"
| summarize 
    TotalCalls = sum(value),
    AvgLatency = avg(todouble(customDimensions["latency_ms"])),
    ErrorRate = todouble(countif(customDimensions["success"] == "false")) / count() * 100
by tostring(customDimensions["agent.name"])
```

**Cost Analysis:**
```kusto
customMetrics
| where name == "maf.tokens.used"
| extend cost = value * 0.00003  // Adjust per your model pricing
| summarize TotalCost = sum(cost) by bin(timestamp, 1h)
```

**Error Tracking:**
```kusto
customMetrics
| where name == "maf.agent.calls" and customDimensions["success"] == "false"
| project timestamp, agent = tostring(customDimensions["agent.name"])
| order by timestamp desc
```

## ğŸ¯ Key Benefits

### For Development
- âœ… Structured code organization
- âœ… Reusable LLMOps components
- âœ… Easy integration into existing agents
- âœ… Clear separation of concerns

### For Operations
- âœ… Real-time cost tracking
- âœ… Budget enforcement
- âœ… Quality monitoring
- âœ… Full observability with App Insights

### For Business
- âœ… Cost control and optimization
- âœ… Quality assurance
- âœ… Audit trails
- âœ… Performance metrics

## ğŸ“– Related Resources

- [MAF Documentation](https://github.com/microsoft/agent-framework)
- [Azure AI Foundry](https://ai.azure.com)
- [Application Insights](https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview)
- [OpenTelemetry Python](https://opentelemetry.io/docs/languages/python/)

## ğŸ¤ Contributing

When adding new LLMOps capabilities:
1. Create module in `llmops/`
2. Add imports to `__init__.py`
3. Update this README
4. Create example usage
5. Add tests (future)

## ğŸ”„ Agent Lifecycle Management

**NEW**: Prevent agent proliferation in Azure AI Foundry!

### The Problem
Every time `ProductionAgent` was instantiated, a **new agent was created in Foundry**, leading to resource proliferation and unnecessary costs.

### The Solution
`ProductionAgentManager` provides centralized agent lifecycle management:
- âœ… Agent registry with reuse capability
- âœ… Prevents duplicate agents in Foundry
- âœ… Thread-safe operations
- âœ… Usage tracking and statistics
- âœ… Proper cleanup on shutdown

### Quick Example
```python
from production_agent_with_lifecycle import ProductionAgent

# First instance creates agent in Foundry
agent1 = ProductionAgent(
    agent_name="market_analyst",
    instructions="You are a market analyst...",
    enable_web_search=True,
    reuse_agent=True  # Enable agent reuse (default)
)
await agent1.run("What's NVIDIA's P/E ratio?")

# Second instance REUSES the same agent (not created again!)
agent2 = ProductionAgent(
    agent_name="market_analyst",
    instructions="You are a market analyst...",
    enable_web_search=True,
    reuse_agent=True
)
await agent2.run("What about Microsoft?")  # Reuses agent
```

### Documentation
- **[AGENT_LIFECYCLE_MANAGEMENT.md](AGENT_LIFECYCLE_MANAGEMENT.md)** - Complete technical guide
- **[LIFECYCLE_SUMMARY.md](LIFECYCLE_SUMMARY.md)** - Team overview and migration strategy
- **[LIFECYCLE_QUICK_REFERENCE.md](LIFECYCLE_QUICK_REFERENCE.md)** - Quick reference guide

### Test It
```bash
cd AQ-CODE/llmops

# Demo 1: Lifecycle manager standalone
python core/agent_lifecycle_manager.py

# Demo 2: Production agent with lifecycle
python examples/production_agent_with_lifecycle.py
```

### Key Benefits
- ğŸ¯ **90% reduction** in Foundry agent resources
- ğŸ’° **Cost savings** from eliminating duplicate agents
- ğŸ“Š **Usage tracking** per agent
- ğŸ”„ **Agent reuse** across sessions
- ğŸ§¹ **Proper cleanup** with centralized management

---

## ğŸ’¡ Next Steps

1. **Run the examples**: 
   - `python examples/example_production_agent.py`
   - `python examples/production_agent_with_lifecycle.py`
2. **Review documentation**: 
   - Read **[docs/QUICKSTART.md](docs/QUICKSTART.md)** for quick start
   - Read **[docs/AGENT_LIFECYCLE_MANAGEMENT.md](docs/AGENT_LIFECYCLE_MANAGEMENT.md)** for lifecycle management
3. **Integrate into your agents**: Import from `llmops.core` modules
4. **Set up monitoring**: Configure Application Insights dashboards
5. **Implement CI/CD**: Follow deployment best practices from docs

---

**Version:** 2.0  
**Last Updated:** November 6, 2025  
**Maintained by:** AI Solutions Architecture Team
