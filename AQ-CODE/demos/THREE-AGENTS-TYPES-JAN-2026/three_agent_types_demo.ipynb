{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d3e8bd",
   "metadata": {},
   "source": [
    "# Three Agent Types Demo - Microsoft Agent Framework (MAF)\n",
    "\n",
    "This notebook demonstrates the **three types of agents** available in Microsoft Agent Framework and their different chat history management approaches.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Azure AI Agent** (`AzureAIClient`) - Service-managed threads stored server-side\n",
    "2. **Azure OpenAI Chat Completion** (`AzureOpenAIChatClient`) - Client-managed history with full control\n",
    "3. **Azure OpenAI Responses** (`AzureOpenAIResponsesClient`) - Flexible history (both service and custom)\n",
    "\n",
    "Each demo shows:\n",
    "- How to create and configure each agent type\n",
    "- Environment variables required for each\n",
    "- Multi-turn conversations demonstrating memory/context handling\n",
    "- When to use each agent type based on your requirements\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+ with packages: `agent-framework`, `agent-framework-azure-ai`, `azure-identity`\n",
    "- Azure CLI authentication: Run `az login` before executing cells\n",
    "- Azure AI Foundry project (for Azure AI Agent)\n",
    "- Azure OpenAI resource (for Chat and Responses agents)\n",
    "\n",
    "**Note**: Each agent type uses different environment variable names - see setup cell below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1a36f",
   "metadata": {},
   "source": [
    "## Setup: Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "env_path = Path.cwd() / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"‚úÖ Loaded .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using system environment variables\")\n",
    "\n",
    "# Verify required variables\n",
    "print(\"\\n=== Azure AI Agent Variables ===\")\n",
    "print(f\"AZURE_AI_PROJECT_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_AI_PROJECT_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_AI_MODEL_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_AI_MODEL_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n=== Azure OpenAI Chat Completion Variables ===\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n=== Azure OpenAI Responses Variables ===\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Note: Each agent type uses DIFFERENT deployment variable names!\")\n",
    "print(\"See: AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md for details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0bc8a",
   "metadata": {},
   "source": [
    "## 1. Azure AI Agent (`AzureAIClient`)\n",
    "\n",
    "**Uses**: Azure AI Agents Service (azure-ai-projects SDK backend)  \n",
    "**Chat History**: Service-managed only (threads stored server-side)  \n",
    "**Best For**: Production scenarios with hosted infrastructure\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_AI_PROJECT_ENDPOINT`\n",
    "- `AZURE_AI_MODEL_DEPLOYMENT_NAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56049c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agent_framework.azure import AzureAIClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "async def demo_azure_ai_agent():\n",
    "    print(\"\\n=== Azure AI Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_AI_PROJECT_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIClient(credential=credential).create_agent(\n",
    "            name=\"AzureAIAgent\",\n",
    "            instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "        ) as agent,\n",
    "    ):\n",
    "        print(\"‚úÖ Azure AI Agent created successfully\")\n",
    "        print(\"üìù Sending query...\")\n",
    "        \n",
    "        # Note: No thread needed for single-turn interactions\n",
    "        # For multi-turn conversations, pass thread=AgentThread()\n",
    "        result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "        print(f\"ü§ñ Response: {result.text}\")\n",
    "        print(f\"üíæ Chat History: Service-managed (thread ID: {result.thread_id if hasattr(result, 'thread_id') else 'N/A'})\")\n",
    "\n",
    "\n",
    "# Run the demoawait demo_azure_ai_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28b9cd",
   "metadata": {},
   "source": [
    "## 1b. Azure AI Agent - Explicit Thread Management (Advanced Pattern - V2 API)\n",
    "\n",
    "The previous demo used `agent.run()` which abstracts thread management. This demo shows the **low-level Azure AI Foundry Agents V2 API** using `AIProjectClient` for explicit control over:\n",
    "\n",
    "- **Threads**: Conversation sessions (max 100,000 messages per thread)\n",
    "- **Messages**: Individual communications added to threads\n",
    "- **Runs**: Agent invocations to process thread messages\n",
    "- **Run Status**: Monitoring execution (queued ‚Üí in_progress ‚Üí completed)\n",
    "\n",
    "**What is the V2 API?**\n",
    "\n",
    "Azure AI Foundry Agents V2 introduces:\n",
    "- ‚úÖ **Agent Versioning**: Each agent configuration is saved as an immutable version\n",
    "- ‚úÖ **`create_version()` method**: Replaces the older `create_agent()` approach\n",
    "- ‚úÖ **`PromptAgentDefinition`**: Structured agent configuration\n",
    "- ‚úÖ **Version History**: Track all changes, compare configurations, and rollback\n",
    "- ‚úÖ **Production Stability**: Immutable versions prevent accidental overwrites\n",
    "\n",
    "**Why use this pattern?**\n",
    "- Production systems requiring external integrations\n",
    "- Custom logging, monitoring, or debugging workflows\n",
    "- Explicit thread persistence and lifecycle management\n",
    "- Access to intermediate run states\n",
    "- Version control for agent configurations\n",
    "\n",
    "**What you'll see:**\n",
    "The code below implements the complete 7-step workflow using V2 API: create versioned agent ‚Üí create thread ‚Üí add message ‚Üí create run ‚Üí poll status ‚Üí retrieve messages ‚Üí follow-up interaction ‚Üí cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdf2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Azure AI Agent - Explicit Thread Management ===\n",
      "\n",
      "1Ô∏è‚É£ Creating agent...\n",
      "   ‚úÖ Agent created: ThreadDemoAgent (version 1)\n",
      "\n",
      "2Ô∏è‚É£ Creating thread...\n",
      "   ‚úÖ Thread created: thread_EPjWAes0YSVfeHiiRaBPDGig\n",
      "   üíæ This thread persists on server - can resume later\n",
      "\n",
      "3Ô∏è‚É£ Adding message to thread...\n",
      "   ‚úÖ Message added: msg_MUqvDbJWgOH02CZk3bLq4wPO\n",
      "\n",
      "4Ô∏è‚É£ Creating and processing run...\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(invalid_value) Invalid 'assistant_id': 'ThreadDemoAgent'. Expected an ID that begins with 'asst'.\nCode: invalid_value\nMessage: Invalid 'assistant_id': 'ThreadDemoAgent'. Expected an ID that begins with 'asst'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    114\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üí° Thread \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m persists server-side until explicitly deleted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Run the demo\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m demo_explicit_thread_management()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mdemo_explicit_thread_management\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Step 4: Create and process run (use agent name, not versioned ID)\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m4Ô∏è‚É£ Creating and processing run...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m run = \u001b[38;5;28;01mawait\u001b[39;00m agents_client.runs.create_and_process(\n\u001b[32m     61\u001b[39m     thread_id=thread.id,\n\u001b[32m     62\u001b[39m     agent_id=agent_name  \u001b[38;5;66;03m# Use agent name instead of agent.id\u001b[39;00m\n\u001b[32m     63\u001b[39m )\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ‚úÖ Run completed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run.status == \u001b[33m\"\u001b[39m\u001b[33mfailed\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/agent-framework-public/.venv/lib/python3.12/site-packages/azure/core/tracing/decorator_async.py:119\u001b[39m, in \u001b[36mdistributed_trace_async.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/agent-framework-public/.venv/lib/python3.12/site-packages/azure/ai/agents/aio/operations/_patch.py:537\u001b[39m, in \u001b[36mRunsOperations.create_and_process\u001b[39m\u001b[34m(self, thread_id, agent_id, include, model, instructions, additional_instructions, additional_messages, toolset, temperature, top_p, max_prompt_tokens, max_completion_tokens, truncation_strategy, tool_choice, response_format, parallel_tool_calls, metadata, run_handler, polling_interval, **kwargs)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates a new run for an agent thread and processes the run.\u001b[39;00m\n\u001b[32m    450\u001b[39m \n\u001b[32m    451\u001b[39m \u001b[33;03m:param thread_id: The identifier of the thread to run.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    534\u001b[39m \u001b[33;03m:raises ~azure.core.exceptions.HttpResponseError:\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    536\u001b[39m \u001b[38;5;66;03m# Create and initiate the run with additional parameters\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m run = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create(\n\u001b[32m    538\u001b[39m     thread_id=thread_id,\n\u001b[32m    539\u001b[39m     agent_id=agent_id,\n\u001b[32m    540\u001b[39m     include=include,\n\u001b[32m    541\u001b[39m     model=model,\n\u001b[32m    542\u001b[39m     instructions=instructions,\n\u001b[32m    543\u001b[39m     additional_instructions=additional_instructions,\n\u001b[32m    544\u001b[39m     additional_messages=additional_messages,\n\u001b[32m    545\u001b[39m     tools=toolset.definitions \u001b[38;5;28;01mif\u001b[39;00m toolset \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    546\u001b[39m     tool_resources=toolset.resources \u001b[38;5;28;01mif\u001b[39;00m toolset \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    547\u001b[39m     temperature=temperature,\n\u001b[32m    548\u001b[39m     top_p=top_p,\n\u001b[32m    549\u001b[39m     max_prompt_tokens=max_prompt_tokens,\n\u001b[32m    550\u001b[39m     max_completion_tokens=max_completion_tokens,\n\u001b[32m    551\u001b[39m     truncation_strategy=truncation_strategy,\n\u001b[32m    552\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    553\u001b[39m     response_format=response_format,\n\u001b[32m    554\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    555\u001b[39m     metadata=metadata,\n\u001b[32m    556\u001b[39m     **kwargs,\n\u001b[32m    557\u001b[39m )\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# Monitor and process the run status\u001b[39;00m\n\u001b[32m    560\u001b[39m run_handler_obj = run_handler \u001b[38;5;129;01mor\u001b[39;00m _models.AsyncRunHandler()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/agent-framework-public/.venv/lib/python3.12/site-packages/azure/core/tracing/decorator_async.py:119\u001b[39m, in \u001b[36mdistributed_trace_async.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/agent-framework-public/.venv/lib/python3.12/site-packages/azure/ai/agents/aio/operations/_patch.py:422\u001b[39m, in \u001b[36mRunsOperations.create\u001b[39m\u001b[34m(self, thread_id, body, agent_id, include, model, instructions, additional_instructions, additional_messages, tools, tool_resources, temperature, top_p, max_prompt_tokens, max_completion_tokens, truncation_strategy, tool_choice, response_format, parallel_tool_calls, metadata, **kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid combination of arguments provided.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/agent-framework-public/.venv/lib/python3.12/site-packages/azure/core/tracing/decorator_async.py:119\u001b[39m, in \u001b[36mdistributed_trace_async.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/agent-framework-public/.venv/lib/python3.12/site-packages/azure/ai/agents/aio/operations/_operations.py:1608\u001b[39m, in \u001b[36mRunsOperations.create\u001b[39m\u001b[34m(self, thread_id, body, agent_id, include, model, instructions, additional_instructions, additional_messages, tools, tool_resources, stream_parameter, temperature, top_p, max_prompt_tokens, max_completion_tokens, truncation_strategy, tool_choice, response_format, parallel_tool_calls, metadata, **kwargs)\u001b[39m\n\u001b[32m   1606\u001b[39m     map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m   1607\u001b[39m     error = _failsafe_deserialize(_models.AgentV1Error, response)\n\u001b[32m-> \u001b[39m\u001b[32m1608\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response, model=error)\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[32m   1611\u001b[39m     deserialized = response.iter_bytes()\n",
      "\u001b[31mHttpResponseError\u001b[39m: (invalid_value) Invalid 'assistant_id': 'ThreadDemoAgent'. Expected an ID that begins with 'asst'.\nCode: invalid_value\nMessage: Invalid 'assistant_id': 'ThreadDemoAgent'. Expected an ID that begins with 'asst'."
     ]
    }
   ],
   "source": [
    "\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "async def demo_explicit_thread_management():\n",
    "    \"\"\"\n",
    "    Demonstrates explicit thread, run, and message management\n",
    "    using Azure AI Foundry Agents V2 API.\n",
    "    \n",
    "    V2 API Features:\n",
    "    - Agent versioning with create_version()\n",
    "    - Immutable agent versions for production stability\n",
    "    - PromptAgentDefinition for agent configuration\n",
    "    - Version-based agent retrieval and management\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Azure AI Agent - Explicit Thread Management (V2 API) ===\")\n",
    "    \n",
    "    if not os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_AI_PROJECT_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(\n",
    "            endpoint=os.getenv('AZURE_AI_PROJECT_ENDPOINT'),\n",
    "            credential=credential\n",
    "        ) as project_client\n",
    "    ):\n",
    "        # Step 1: Create an agent using V2 API (create_version)\n",
    "        print(\"\\n1Ô∏è‚É£ Creating agent (V2 API - versioned agent)...\")\n",
    "        agent_name = \"ThreadDemoAgent\"\n",
    "        agent_version = await project_client.agents.create_version(\n",
    "            agent_name=agent_name,\n",
    "            definition=PromptAgentDefinition(\n",
    "                model=os.getenv('AZURE_AI_MODEL_DEPLOYMENT_NAME', 'gpt-4o'),\n",
    "                instructions=\"You are a helpful assistant demonstrating thread management.\"\n",
    "            ),\n",
    "            description=\"Demo agent for explicit thread management (V2 API)\"\n",
    "        )\n",
    "        print(f\"   ‚úÖ Agent created: {agent_version.name} (version {agent_version.version})\")\n",
    "        print(f\"   üì¶ V2 Feature: This version is immutable and can be referenced as '{agent_name}:{agent_version.version}'\")\n",
    "        \n",
    "        # Get the agent to retrieve its actual agent ID (asst_xxx format)\n",
    "        agent = await project_client.agents.get(agent_name=agent_name, agent_version=agent_version.version)\n",
    "        agent_id = agent.agent_id  # This should be in format 'asst_xxx'\n",
    "        print(f\"   üîë Agent ID: {agent_id}\")\n",
    "        \n",
    "        # For thread/message/run operations, we need the standalone AgentsClient\n",
    "        from azure.ai.agents.aio import AgentsClient\n",
    "        agents_client = AgentsClient(\n",
    "            endpoint=os.getenv('AZURE_AI_PROJECT_ENDPOINT'),\n",
    "            credential=credential\n",
    "        )\n",
    "        \n",
    "        # Step 2: Create a thread (conversation session)\n",
    "        print(\"\\n2Ô∏è‚É£ Creating thread...\")\n",
    "        thread = await agents_client.threads.create()\n",
    "        print(f\"   ‚úÖ Thread created: {thread.id}\")\n",
    "        print(f\"   üíæ This thread persists on server - can resume later\")\n",
    "        \n",
    "        # Step 3: Add a message to the thread\n",
    "        print(\"\\n3Ô∏è‚É£ Adding message to thread...\")\n",
    "        message = await agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"What are the key benefits of thread-based conversation management?\"\n",
    "        )\n",
    "        print(f\"   ‚úÖ Message added: {message.id}\")\n",
    "        \n",
    "        # Step 4: Create and process run (use the actual agent ID)\n",
    "        print(\"\\n4Ô∏è‚É£ Creating and processing run...\")\n",
    "        run = await agents_client.runs.create_and_process(\n",
    "            thread_id=thread.id,\n",
    "            agent_id=agent_id  # Use the actual agent ID (asst_xxx) from V2 API\n",
    "        )\n",
    "        print(f\"   ‚úÖ Run completed: {run.status}\")\n",
    "        \n",
    "        if run.status == \"failed\":\n",
    "            print(f\"   ‚ùå Run failed: {run.last_error}\")\n",
    "            await project_client.agents.delete(agent_name=agent_name, agent_version=agent_version.version)\n",
    "            await agents_client.close()\n",
    "            return\n",
    "        \n",
    "        # Step 5: Retrieve and display messages\n",
    "        print(\"\\n5Ô∏è‚É£ Retrieving messages from thread...\")\n",
    "        messages = await agents_client.messages.list(thread_id=thread.id)\n",
    "        \n",
    "        print(\"\\nüìù Conversation:\")\n",
    "        for msg in messages.data:\n",
    "            role = \"üôã User\" if msg.role == \"user\" else \"ü§ñ Agent\"\n",
    "            if msg.text_messages:\n",
    "                for text_msg in msg.text_messages:\n",
    "                    print(f\"{role}: {text_msg.text.value}\")\n",
    "        \n",
    "        # Demonstrate thread persistence - add another message\n",
    "        print(\"\\n6Ô∏è‚É£ Adding follow-up message (shows thread persistence)...\")\n",
    "        await agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"Can you summarize the key point in one sentence?\"\n",
    "        )\n",
    "        \n",
    "        # Create another run\n",
    "        run2 = await agents_client.runs.create_and_process(\n",
    "            thread_id=thread.id,\n",
    "            agent_id=agent_id  # Use the actual agent ID\n",
    "        )\n",
    "        \n",
    "        if run2.status == \"failed\":\n",
    "            print(f\"   ‚ùå Run failed: {run2.last_error}\")\n",
    "        else:\n",
    "            # Get updated messages\n",
    "            messages = await agents_client.messages.list(thread_id=thread.id)\n",
    "            for msg in messages.data:\n",
    "                if msg.role == \"assistant\" and msg.run_id == run2.id:\n",
    "                    if msg.text_messages:\n",
    "                        for text_msg in msg.text_messages:\n",
    "                            print(f\"ü§ñ Follow-up response: {text_msg.text.value}\")\n",
    "                    break\n",
    "        \n",
    "        # Cleanup\n",
    "        print(\"\\n7Ô∏è‚É£ Cleanup...\")\n",
    "        await project_client.agents.delete(agent_name=agent_name, agent_version=agent_version.version)\n",
    "        await agents_client.close()\n",
    "        print(\"   ‚úÖ Agent deleted\")\n",
    "        print(f\"   üí° Thread {thread.id} persists server-side until explicitly deleted\")\n",
    "        print(f\"   üì¶ V2 Feature: Version {agent_version.version} is immutable - deletion removes entire agent\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_explicit_thread_management()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c4e24",
   "metadata": {},
   "source": [
    "### Demo 1b: Explicit Thread Management Implementation\n",
    "\n",
    "This cell demonstrates the **low-level Azure AI Foundry Agent API** using `AIProjectClient` directly. Unlike `agent.run()` which abstracts thread management, this shows the complete 8-step workflow:\n",
    "\n",
    "1. Create agent ‚Üí 2. Create thread ‚Üí 3. Add message ‚Üí 4. Create run ‚Üí 5. Poll status ‚Üí 6. Retrieve messages ‚Üí 7. Follow-up interaction ‚Üí 8. Cleanup\n",
    "\n",
    "This pattern gives you full control over the agent lifecycle and is recommended for production scenarios where you need to:\n",
    "- Integrate with external systems\n",
    "- Implement custom logging or monitoring\n",
    "- Manage thread persistence explicitly\n",
    "- Access intermediate run states for debugging\n",
    "\n",
    "**Run the cell below to see each step in action:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d4011",
   "metadata": {},
   "source": [
    "## 1b. Azure AI Agent - Explicit Thread Management (Advanced)\n",
    "\n",
    "The previous demo used `agent.run()` which abstracts thread management. For production scenarios, you may want explicit control over threads, runs, and messages as described in the [Azure AI Foundry documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/threads-runs-messages).\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Thread**: A conversation session storing messages (max 100,000 messages per thread)\n",
    "- **Messages**: Individual communications (text, files) within a thread\n",
    "- **Run**: Invocation of the agent to process thread messages and generate responses\n",
    "- **Run Status**: Monitor run lifecycle (queued ‚Üí in_progress ‚Üí completed)\n",
    "\n",
    "This pattern is useful when you need:\n",
    "- Fine-grained control over thread lifecycle\n",
    "- Access to intermediate run states\n",
    "- Custom message handling or storage\n",
    "- Integration with external systems tracking conversation state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43d5ba",
   "metadata": {},
   "source": [
    "### Visual Workflow\n",
    "\n",
    "![Azure AI Agent Run Workflow](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/media/run-thread-model.png?view=foundry-classic)\n",
    "\n",
    "*Source: [Microsoft Learn - Threads, runs, and messages](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/threads-runs-messages?view=foundry-classic)*\n",
    "\n",
    "The diagram above shows the complete lifecycle of an agent interaction using explicit thread management. Our demo below implements all these steps programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d1147",
   "metadata": {},
   "source": [
    "## 2. Azure OpenAI Chat Completion (`AzureOpenAIChatClient`)\n",
    "\n",
    "**Uses**: Azure OpenAI Chat Completion API  \n",
    "**Chat History**: Custom/client-managed only (you control storage)  \n",
    "**Best For**: Custom storage requirements, full control over conversation state\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME` ‚ö†Ô∏è Note: **CHAT**_DEPLOYMENT\n",
    "- `AZURE_OPENAI_API_VERSION` (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "async def demo_azure_openai_chat():\n",
    "    print(\"\\n=== Azure OpenAI Chat Completion Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_OPENAI_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_ENDPOINT\")\n",
    "        return\n",
    "    if not os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        print(\"üí° This is different from AZURE_OPENAI_DEPLOYMENT_NAME!\")\n",
    "        return\n",
    "    \n",
    "    agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "        name=\"ChatCompletionAgent\",\n",
    "        instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Azure OpenAI Chat Completion Agent created successfully\")\n",
    "    print(\"üìù Sending query...\")\n",
    "    \n",
    "    # Note: No thread needed for single-turn interactions\n",
    "    # For multi-turn conversations, pass thread=AgentThread()\n",
    "    result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "    print(f\"ü§ñ Response: {result.text}\")\n",
    "    print(f\"üíæ Chat History: Client-managed (you must implement storage)\")\n",
    "\n",
    "\n",
    "# Run the demoawait demo_azure_openai_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c65cec",
   "metadata": {},
   "source": [
    "## 3. Azure OpenAI Responses (`AzureOpenAIResponsesClient`)\n",
    "\n",
    "**Uses**: Azure OpenAI Responses API  \n",
    "**Chat History**: Both service-managed AND custom (most flexible!)  \n",
    "**Best For**: Scenarios requiring both convenience and customization\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME` ‚ö†Ô∏è Note: **RESPONSES**_DEPLOYMENT\n",
    "- `AZURE_OPENAI_API_VERSION` (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99782db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "async def demo_azure_openai_responses():\n",
    "    print(\"\\n=== Azure OpenAI Responses Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_OPENAI_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    # Check if endpoint is Azure OpenAI (not Azure AI Foundry)\n",
    "    endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', '')\n",
    "    if not endpoint.endswith('.openai.azure.com/') and not endpoint.endswith('.openai.azure.com'):\n",
    "        print(\"‚ö†Ô∏è  Azure OpenAI Responses API is NOT available on Azure AI Foundry endpoints\")\n",
    "        print(f\"   Your endpoint: {endpoint}\")\n",
    "        print(\"   Required: https://your-resource.openai.azure.com/\")\n",
    "        print(\"\\nüí° The Responses API only works with native Azure OpenAI Service endpoints.\")\n",
    "        print(\"üí° Since you're using Azure AI Foundry, this demo will be skipped.\")\n",
    "        print(\"üí° Use AzureAIClient (Demo #1) or AzureOpenAIChatClient (Demo #2) instead.\")\n",
    "        return\n",
    "    \n",
    "    if not os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME\")\n",
    "        print(\"üí° This is different from AZURE_OPENAI_DEPLOYMENT_NAME!\")\n",
    "        print(\"üí° Set: AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=your-deployment-name\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        agent = AzureOpenAIResponsesClient(credential=AzureCliCredential()).create_agent(\n",
    "            name=\"ResponsesAgent\",\n",
    "            instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Azure OpenAI Responses Agent created successfully\")\n",
    "        print(\"üìù Sending query...\")\n",
    "        \n",
    "        # Note: No thread needed for single-turn interactions\n",
    "        # For multi-turn conversations, pass thread=AgentThread()\n",
    "        result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "        print(f\"ü§ñ Response: {result.text}\")\n",
    "        print(f\"üíæ Chat History: Service-managed OR custom (your choice!)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"\\nüí° This typically means the Responses API is not available on your endpoint.\")\n",
    "\n",
    "\n",
    "# Run the demoawait demo_azure_openai_responses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444a126",
   "metadata": {},
   "source": [
    "## Comparison: Chat History Management\n",
    "\n",
    "Let's demonstrate multi-turn conversations with each agent type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demo_multi_turn_conversations():\n",
    "    print(\"\\n=== Multi-Turn Conversation Comparison ===\")\n",
    "    \n",
    "    # Import async credential and AgentThread for maintaining conversation state\n",
    "    from azure.identity.aio import AzureCliCredential as AsyncAzureCliCredential\n",
    "    from agent_framework import AgentThread\n",
    "    \n",
    "    # Azure AI Agent - Service-managed history\n",
    "    if os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"\\n1Ô∏è‚É£ Azure AI Agent (Service-managed history):\")\n",
    "        async with (\n",
    "            AsyncAzureCliCredential() as credential,\n",
    "            AzureAIClient(credential=credential).create_agent(\n",
    "                name=\"MultiTurnAgent\",\n",
    "                instructions=\"Remember the conversation context.\",\n",
    "            ) as agent,\n",
    "        ):\n",
    "            # Create a thread to maintain conversation state\n",
    "            thread = AgentThread()\n",
    "            \n",
    "            # First turn\n",
    "            result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "            print(f\"   User: My favorite color is blue.\")\n",
    "            print(f\"   Agent: {result1.text}\")\n",
    "            \n",
    "            # Second turn (agent should remember because we're using the same thread)\n",
    "            result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "            print(f\"   User: What's my favorite color?\")\n",
    "            print(f\"   Agent: {result2.text}\")\n",
    "            print(f\"   ‚úÖ Service remembers context via AgentThread object\")\n",
    "    \n",
    "    # Azure OpenAI Chat - Client-managed history\n",
    "    if os.getenv('AZURE_OPENAI_ENDPOINT') and os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME'):\n",
    "        print(\"\\n2Ô∏è‚É£ Azure OpenAI Chat (Client-managed history):\")\n",
    "        agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "            instructions=\"Remember the conversation context.\",\n",
    "        )\n",
    "        \n",
    "        # Create a thread to maintain conversation state\n",
    "        thread = AgentThread()\n",
    "        \n",
    "        result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "        print(f\"   User: My favorite color is blue.\")\n",
    "        print(f\"   Agent: {result1.text}\")\n",
    "        \n",
    "        result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "        print(f\"   User: What's my favorite color?\")\n",
    "        print(f\"   Agent: {result2.text}\")\n",
    "        print(f\"   ‚úÖ AgentThread stores history client-side\")\n",
    "        \n",
    "    # Azure OpenAI Responses - Flexible history\n",
    "    if os.getenv('AZURE_OPENAI_ENDPOINT') and os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME'):\n",
    "        endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', '')\n",
    "        if endpoint.endswith('.openai.azure.com/') or endpoint.endswith('.openai.azure.com'):\n",
    "            print(\"\\n3Ô∏è‚É£ Azure OpenAI Responses (Flexible history):\")\n",
    "            agent = AzureOpenAIResponsesClient(credential=AzureCliCredential()).create_agent(\n",
    "                instructions=\"Remember the conversation context.\",\n",
    "            )\n",
    "            \n",
    "            # Create a thread to maintain conversation state\n",
    "            thread = AgentThread()\n",
    "            \n",
    "            result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "            print(f\"   User: My favorite color is blue.\")\n",
    "            print(f\"   Agent: {result1.text}\")\n",
    "            \n",
    "            result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "            print(f\"   User: What's my favorite color?\")\n",
    "            print(f\"   Agent: {result2.text}\")\n",
    "            print(f\"   ‚úÖ Can use service OR custom history via AgentThread\")\n",
    "        else:\n",
    "            print(\"\\n3Ô∏è‚É£ Azure OpenAI Responses (Skipped - requires .openai.azure.com endpoint)\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_multi_turn_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd8b40",
   "metadata": {},
   "source": [
    "## Summary: When to Use Each Agent Type\n",
    "\n",
    "### ‚úÖ Use Azure AI Agent when:\n",
    "- You want service-managed conversation threads\n",
    "- Building production apps with Azure AI Foundry/Projects\n",
    "- Need hosted agent infrastructure\n",
    "- Want automatic thread management\n",
    "\n",
    "### ‚úÖ Use Azure OpenAI Chat Completion when:\n",
    "- You need full control over chat history storage\n",
    "- Implementing custom persistence (database, Redis, etc.)\n",
    "- Want to manage conversation state manually\n",
    "- Building custom chat applications\n",
    "\n",
    "### ‚úÖ Use Azure OpenAI Responses when:\n",
    "- You want the flexibility of both options\n",
    "- Need structured response generation\n",
    "- Want to choose between service or custom history\n",
    "- Building applications that may evolve requirements\n",
    "\n",
    "---\n",
    "\n",
    "## Complete .env File Template\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL**: Each agent type uses **different deployment variable names**!\n",
    "\n",
    "Create a `.env` file in your project root with these variables:\n",
    "\n",
    "```bash\n",
    "# ========================================\n",
    "# Azure AI Agent (AzureAIClient)\n",
    "# ========================================\n",
    "AZURE_AI_PROJECT_ENDPOINT=\"https://your-ai-services.services.ai.azure.com/api/projects/your-project\"\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=\"gpt-4o\"\n",
    "\n",
    "# ========================================\n",
    "# Azure OpenAI Chat Completion (AzureOpenAIChatClient)\n",
    "# ========================================\n",
    "AZURE_OPENAI_ENDPOINT=\"https://your-resource.openai.azure.com/\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"gpt-4o\"        # Note: CHAT_DEPLOYMENT\n",
    "AZURE_OPENAI_API_VERSION=\"2024-10-21\"\n",
    "\n",
    "# ========================================\n",
    "# Azure OpenAI Responses (AzureOpenAIResponsesClient)\n",
    "# ========================================\n",
    "# Uses same AZURE_OPENAI_ENDPOINT as above\n",
    "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=\"gpt-4o\"   # Note: RESPONSES_DEPLOYMENT\n",
    "\n",
    "# Authentication: Run 'az login' in terminal\n",
    "```\n",
    "\n",
    "**Important**: \n",
    "- Don't commit your `.env` file to git! Add it to `.gitignore`.\n",
    "- See `AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md` for detailed explanation of variable naming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b6420",
   "metadata": {},
   "source": [
    "## üéì Key Learnings from This Demo\n",
    "\n",
    "### 1. Conversation State Management\n",
    "**Critical Discovery**: Without passing an `AgentThread` object, each `agent.run()` call is completely independent - the agent has NO memory of previous interactions.\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - Each call is a new conversation\n",
    "result1 = await agent.run(\"My favorite color is blue.\")\n",
    "result2 = await agent.run(\"What's my favorite color?\")  # Agent won't remember!\n",
    "\n",
    "# ‚úÖ Correct - Use AgentThread to maintain conversation state\n",
    "from agent_framework import AgentThread\n",
    "thread = AgentThread()\n",
    "result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "result2 = await agent.run(\"What's my favorite color?\", thread=thread)  # Agent remembers!\n",
    "```\n",
    "\n",
    "### 2. Environment Variable Naming Confusion\n",
    "Each agent type uses **different** deployment variable names. This is intentional to allow using different models for different agent types:\n",
    "\n",
    "| Agent Type | Deployment Variable Name |\n",
    "|------------|-------------------------|\n",
    "| Azure AI Agent | `AZURE_AI_MODEL_DEPLOYMENT_NAME` |\n",
    "| Azure OpenAI Chat | `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME` |\n",
    "| Azure OpenAI Responses | `AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME` |\n",
    "\n",
    "**Why?** This allows flexibility:\n",
    "```bash\n",
    "# You can use different models for different purposes\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=\"gpt-4o\"              # Production agent\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"gpt-4o-mini\"      # Cost-effective chat\n",
    "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=\"gpt-4o\"      # Advanced responses\n",
    "```\n",
    "\n",
    "### 3. Azure OpenAI Responses API Endpoint Requirements\n",
    "The Responses API has strict endpoint requirements:\n",
    "- ‚úÖ **Works with**: `https://your-resource.openai.azure.com/` (Native Azure OpenAI)\n",
    "- ‚ùå **Does NOT work with**: `https://your-resource.services.ai.azure.com/` (Azure AI Foundry)\n",
    "\n",
    "**Why?** The Responses API is a preview feature only available on native Azure OpenAI Service endpoints. The SDK checks for `.openai.azure.com` suffix before allowing the API call.\n",
    "\n",
    "### 4. Async Context Manager Requirements\n",
    "Azure AI Agent requires async credentials when using context managers:\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - Sync credential with async context manager\n",
    "from azure.identity import AzureCliCredential\n",
    "async with AzureCliCredential() as cred:  # TypeError!\n",
    "\n",
    "# ‚úÖ Correct - Async credential for async context\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "async with AzureCliCredential() as cred:  # Works!\n",
    "```\n",
    "\n",
    "### 5. Chat History Storage Differences\n",
    "\n",
    "| Agent Type | History Storage | When to Use |\n",
    "|------------|----------------|-------------|\n",
    "| **Azure AI Agent** | Service-managed (server-side) | Production apps, want Azure to handle persistence |\n",
    "| **Azure OpenAI Chat** | Client-managed (you store it) | Custom storage (DB, Redis), full control |\n",
    "| **Azure OpenAI Responses** | Both options available | Most flexible, can choose per use case |\n",
    "\n",
    "**Important**: Even though storage differs, all three use `AgentThread()` locally to maintain conversation state during execution.\n",
    "\n",
    "### 6. Authentication Pattern\n",
    "All demos use Azure CLI authentication:\n",
    "1. Run `az login` in terminal\n",
    "2. Use `AzureCliCredential()` in code\n",
    "3. Azure handles authentication automatically\n",
    "\n",
    "This is the recommended approach for development and testing. Production apps should use Managed Identity or Service Principal authentication.\n",
    "\n",
    "---\n",
    "\n",
    "üí° **See Also**: [AGENT_ENV_VARS_EXPLAINED.md](../docs/AGENT_ENV_VARS_EXPLAINED.md) for detailed explanation of environment variable naming patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19e0cd",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Microsoft Learn - Agent Types](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/?pivots=programming-language-python)\n",
    "- [MAF GitHub - Azure AI Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_ai)\n",
    "- [MAF GitHub - Azure OpenAI Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_openai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
