{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d3e8bd",
   "metadata": {},
   "source": [
    "# Three Agent Types Demo - Microsoft Agent Framework (MAF)\n",
    "\n",
    "This notebook demonstrates the **three types of agents** available in Microsoft Agent Framework and their different chat history management approaches.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Azure AI Agent** (`AzureAIClient`) - Service-managed threads stored server-side\n",
    "2. **Azure OpenAI Chat Completion** (`AzureOpenAIChatClient`) - Client-managed history with full control\n",
    "3. **Azure OpenAI Responses** (`AzureOpenAIResponsesClient`) - Flexible history (both service and custom)\n",
    "\n",
    "Each demo shows:\n",
    "- How to create and configure each agent type\n",
    "- Environment variables required for each\n",
    "- Multi-turn conversations demonstrating memory/context handling\n",
    "- When to use each agent type based on your requirements\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+ with packages: `agent-framework`, `agent-framework-azure-ai`, `azure-identity`\n",
    "- Azure CLI authentication: Run `az login` before executing cells\n",
    "- Azure AI Foundry project (for Azure AI Agent)\n",
    "- Azure OpenAI resource (for Chat and Responses agents)\n",
    "\n",
    "**Note**: Each agent type uses different environment variable names - see setup cell below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1a36f",
   "metadata": {},
   "source": [
    "## Setup: Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1387a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded .env file\n",
      "\n",
      "=== Azure AI Agent Variables ===\n",
      "AZURE_AI_PROJECT_ENDPOINT: ‚úÖ Set\n",
      "AZURE_AI_MODEL_DEPLOYMENT_NAME: ‚úÖ Set\n",
      "\n",
      "=== Azure OpenAI Chat Completion Variables ===\n",
      "AZURE_OPENAI_ENDPOINT: ‚úÖ Set\n",
      "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME: ‚úÖ Set\n",
      "\n",
      "=== Azure OpenAI Responses Variables ===\n",
      "AZURE_OPENAI_ENDPOINT: ‚úÖ Set\n",
      "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME: ‚úÖ Set\n",
      "\n",
      "‚ö†Ô∏è  Note: Each agent type uses DIFFERENT deployment variable names!\n",
      "See: AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md for details\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "env_path = Path.cwd() / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"‚úÖ Loaded .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using system environment variables\")\n",
    "\n",
    "# Verify required variables\n",
    "print(\"\\n=== Azure AI Agent Variables ===\")\n",
    "print(f\"AZURE_AI_PROJECT_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_AI_PROJECT_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_AI_MODEL_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_AI_MODEL_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n=== Azure OpenAI Chat Completion Variables ===\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n=== Azure OpenAI Responses Variables ===\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Note: Each agent type uses DIFFERENT deployment variable names!\")\n",
    "print(\"See: AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md for details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0bc8a",
   "metadata": {},
   "source": [
    "## 1. Azure AI Agent (`AzureAIClient`)\n",
    "\n",
    "**Uses**: Azure AI Agents Service (azure-ai-projects SDK backend)  \n",
    "**Chat History**: Service-managed only (threads stored server-side)  \n",
    "**Best For**: Production scenarios with hosted infrastructure\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_AI_PROJECT_ENDPOINT`\n",
    "- `AZURE_AI_MODEL_DEPLOYMENT_NAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56049c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Azure AI Agent Demo ===\n"
     ]
    },
    {
     "ename": "ServiceInitializationError",
     "evalue": "Azure credential is required when project_client is not provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServiceInitializationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mü§ñ Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müíæ Chat History: Service-managed (thread ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.thread_id\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mhasattr\u001b[39m(result,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m demo_azure_ai_agent()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mdemo_azure_ai_agent\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Create credential first\u001b[39;00m\n\u001b[32m     14\u001b[39m credential = AzureCliCredential()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mAzureAIClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_credential\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredential\u001b[49m\u001b[43m)\u001b[49m.create_agent(\n\u001b[32m     17\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mAzureAIAgent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant. Keep responses concise.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent:\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Azure AI Agent created successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìù Sending query...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GITHUB/agent-framework-public/.venv/lib/python3.12/site-packages/agent_framework_azure_ai/_client.py:163\u001b[39m, in \u001b[36mAzureAIClient.__init__\u001b[39m\u001b[34m(self, project_client, agent_name, agent_version, agent_description, conversation_id, project_endpoint, model_deployment_name, credential, use_latest_version, env_file_path, env_file_encoding, **kwargs)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# Use provided credential\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m credential:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[33m\"\u001b[39m\u001b[33mAzure credential is required when project_client is not provided.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m project_client = AIProjectClient(\n\u001b[32m    165\u001b[39m     endpoint=azure_ai_settings.project_endpoint,\n\u001b[32m    166\u001b[39m     credential=credential,\n\u001b[32m    167\u001b[39m     user_agent=AGENT_FRAMEWORK_USER_AGENT,\n\u001b[32m    168\u001b[39m )\n\u001b[32m    169\u001b[39m should_close_client = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mServiceInitializationError\u001b[39m: Azure credential is required when project_client is not provided."
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agent_framework.azure import AzureAIClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "async def demo_azure_ai_agent():\n",
    "    print(\"\\n=== Azure AI Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_AI_PROJECT_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    # Create credential first\n",
    "    credential = AzureCliCredential()\n",
    "    \n",
    "    async with AzureAIClient(async_credential=credential).create_agent(\n",
    "        name=\"AzureAIAgent\",\n",
    "        instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "    ) as agent:\n",
    "        print(\"‚úÖ Azure AI Agent created successfully\")\n",
    "        print(\"üìù Sending query...\")\n",
    "        \n",
    "        # Note: No thread needed for single-turn interactions\n",
    "        # For multi-turn conversations, pass thread=AgentThread()\n",
    "        result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "        print(f\"ü§ñ Response: {result.text}\")\n",
    "        print(f\"üíæ Chat History: Service-managed (thread ID: {result.thread_id if hasattr(result, 'thread_id') else 'N/A'})\")\n",
    "\n",
    "\n",
    "await demo_azure_ai_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28b9cd",
   "metadata": {},
   "source": [
    "## 1b. Azure AI Agent - Explicit Thread Management (Advanced Pattern - V2 API)\n",
    "\n",
    "The previous demo used `agent.run()` which abstracts thread management. This demo shows the **low-level Azure AI Foundry Agents V2 API** using `AIProjectClient` for explicit control over:\n",
    "\n",
    "- **Threads**: Conversation sessions (max 100,000 messages per thread)\n",
    "- **Messages**: Individual communications added to threads\n",
    "- **Runs**: Agent invocations to process thread messages\n",
    "- **Run Status**: Monitoring execution (queued ‚Üí in_progress ‚Üí completed)\n",
    "\n",
    "**What is the V2 API?**\n",
    "\n",
    "Azure AI Foundry Agents V2 introduces:\n",
    "- ‚úÖ **Agent Versioning**: Each agent configuration is saved as an immutable version\n",
    "- ‚úÖ **`create_version()` method**: Replaces the older `create_agent()` approach\n",
    "- ‚úÖ **`PromptAgentDefinition`**: Structured agent configuration\n",
    "- ‚úÖ **Version History**: Track all changes, compare configurations, and rollback\n",
    "- ‚úÖ **Production Stability**: Immutable versions prevent accidental overwrites\n",
    "\n",
    "**Why use this pattern?**\n",
    "- Production systems requiring external integrations\n",
    "- Custom logging, monitoring, or debugging workflows\n",
    "- Explicit thread persistence and lifecycle management\n",
    "- Access to intermediate run states\n",
    "- Version control for agent configurations\n",
    "\n",
    "**What you'll see:**\n",
    "The code below implements the complete 7-step workflow using V2 API: create versioned agent ‚Üí create thread ‚Üí add message ‚Üí create run ‚Üí poll status ‚Üí retrieve messages ‚Üí follow-up interaction ‚Üí cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdf2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "async def demo_explicit_thread_management():\n",
    "    \"\"\"\n",
    "    Demonstrates explicit thread, run, and message management\n",
    "    using Azure AI Foundry Agents V2 API.\n",
    "    \n",
    "    V2 API Features:\n",
    "    - Agent versioning with create_version()\n",
    "    - Immutable agent versions for production stability\n",
    "    - PromptAgentDefinition for agent configuration\n",
    "    - Version-based agent retrieval and management\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Azure AI Agent - Explicit Thread Management (V2 API) ===\")\n",
    "    \n",
    "    if not os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_AI_PROJECT_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(\n",
    "            endpoint=os.getenv('AZURE_AI_PROJECT_ENDPOINT'),\n",
    "            credential=credential\n",
    "        ) as project_client\n",
    "    ):\n",
    "        # Step 1: Create an agent using V2 API (create_version)\n",
    "        print(\"\\n1Ô∏è‚É£ Creating agent (V2 API - versioned agent)...\")\n",
    "        agent_name = \"ThreadDemoAgent\"\n",
    "        agent_version = await project_client.agents.create_version(\n",
    "            agent_name=agent_name,\n",
    "            definition=PromptAgentDefinition(\n",
    "                model=os.getenv('AZURE_AI_MODEL_DEPLOYMENT_NAME', 'gpt-4o'),\n",
    "                instructions=\"You are a helpful assistant demonstrating thread management.\"\n",
    "            ),\n",
    "            description=\"Demo agent for explicit thread management (V2 API)\"\n",
    "        )\n",
    "        print(f\"   ‚úÖ Agent created: {agent_version.name} (version {agent_version.version})\")\n",
    "        print(f\"   üì¶ V2 Feature: This version is immutable and can be referenced as '{agent_name}:{agent_version.version}'\")\n",
    "        \n",
    "        # Get the agent to retrieve its actual agent ID (asst_xxx format)\n",
    "        agent = await project_client.agents.get(agent_name=agent_name, agent_version=agent_version.version)\n",
    "        agent_id = agent.agent_id  # This should be in format 'asst_xxx'\n",
    "        print(f\"   üîë Agent ID: {agent_id}\")\n",
    "        \n",
    "        # For thread/message/run operations, we need the standalone AgentsClient\n",
    "        from azure.ai.agents.aio import AgentsClient\n",
    "        agents_client = AgentsClient(\n",
    "            endpoint=os.getenv('AZURE_AI_PROJECT_ENDPOINT'),\n",
    "            credential=credential\n",
    "        )\n",
    "        \n",
    "        # Step 2: Create a thread (conversation session)\n",
    "        print(\"\\n2Ô∏è‚É£ Creating thread...\")\n",
    "        thread = await agents_client.threads.create()\n",
    "        print(f\"   ‚úÖ Thread created: {thread.id}\")\n",
    "        print(f\"   üíæ This thread persists on server - can resume later\")\n",
    "        \n",
    "        # Step 3: Add a message to the thread\n",
    "        print(\"\\n3Ô∏è‚É£ Adding message to thread...\")\n",
    "        message = await agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"What are the key benefits of thread-based conversation management?\"\n",
    "        )\n",
    "        print(f\"   ‚úÖ Message added: {message.id}\")\n",
    "        \n",
    "        # Step 4: Create and process run (use the actual agent ID)\n",
    "        print(\"\\n4Ô∏è‚É£ Creating and processing run...\")\n",
    "        run = await agents_client.runs.create_and_process(\n",
    "            thread_id=thread.id,\n",
    "            agent_id=agent_id  # Use the actual agent ID (asst_xxx) from V2 API\n",
    "        )\n",
    "        print(f\"   ‚úÖ Run completed: {run.status}\")\n",
    "        \n",
    "        if run.status == \"failed\":\n",
    "            print(f\"   ‚ùå Run failed: {run.last_error}\")\n",
    "            await project_client.agents.delete(agent_name=agent_name, agent_version=agent_version.version)\n",
    "            await agents_client.close()\n",
    "            return\n",
    "        \n",
    "        # Step 5: Retrieve and display messages\n",
    "        print(\"\\n5Ô∏è‚É£ Retrieving messages from thread...\")\n",
    "        messages = await agents_client.messages.list(thread_id=thread.id)\n",
    "        \n",
    "        print(\"\\nüìù Conversation:\")\n",
    "        for msg in messages.data:\n",
    "            role = \"üôã User\" if msg.role == \"user\" else \"ü§ñ Agent\"\n",
    "            if msg.text_messages:\n",
    "                for text_msg in msg.text_messages:\n",
    "                    print(f\"{role}: {text_msg.text.value}\")\n",
    "        \n",
    "        # Demonstrate thread persistence - add another message\n",
    "        print(\"\\n6Ô∏è‚É£ Adding follow-up message (shows thread persistence)...\")\n",
    "        await agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"Can you summarize the key point in one sentence?\"\n",
    "        )\n",
    "        \n",
    "        # Create another run\n",
    "        run2 = await agents_client.runs.create_and_process(\n",
    "            thread_id=thread.id,\n",
    "            agent_id=agent_id  # Use the actual agent ID\n",
    "        )\n",
    "        \n",
    "        if run2.status == \"failed\":\n",
    "            print(f\"   ‚ùå Run failed: {run2.last_error}\")\n",
    "        else:\n",
    "            # Get updated messages\n",
    "            messages = await agents_client.messages.list(thread_id=thread.id)\n",
    "            for msg in messages.data:\n",
    "                if msg.role == \"assistant\" and msg.run_id == run2.id:\n",
    "                    if msg.text_messages:\n",
    "                        for text_msg in msg.text_messages:\n",
    "                            print(f\"ü§ñ Follow-up response: {text_msg.text.value}\")\n",
    "                    break\n",
    "        \n",
    "        # Cleanup\n",
    "        print(\"\\n7Ô∏è‚É£ Cleanup...\")\n",
    "        await project_client.agents.delete(agent_name=agent_name, agent_version=agent_version.version)\n",
    "        await agents_client.close()\n",
    "        print(\"   ‚úÖ Agent deleted\")\n",
    "        print(f\"   üí° Thread {thread.id} persists server-side until explicitly deleted\")\n",
    "        print(f\"   üì¶ V2 Feature: Version {agent_version.version} is immutable - deletion removes entire agent\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_explicit_thread_management()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c4e24",
   "metadata": {},
   "source": [
    "### Demo 1b: Explicit Thread Management Implementation\n",
    "\n",
    "This cell demonstrates the **low-level Azure AI Foundry Agent API** using `AIProjectClient` directly. Unlike `agent.run()` which abstracts thread management, this shows the complete 8-step workflow:\n",
    "\n",
    "1. Create agent ‚Üí 2. Create thread ‚Üí 3. Add message ‚Üí 4. Create run ‚Üí 5. Poll status ‚Üí 6. Retrieve messages ‚Üí 7. Follow-up interaction ‚Üí 8. Cleanup\n",
    "\n",
    "This pattern gives you full control over the agent lifecycle and is recommended for production scenarios where you need to:\n",
    "- Integrate with external systems\n",
    "- Implement custom logging or monitoring\n",
    "- Manage thread persistence explicitly\n",
    "- Access intermediate run states for debugging\n",
    "\n",
    "**Run the cell below to see each step in action:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d4011",
   "metadata": {},
   "source": [
    "## 1b. Azure AI Agent - Explicit Thread Management (Advanced)\n",
    "\n",
    "The previous demo used `agent.run()` which abstracts thread management. For production scenarios, you may want explicit control over threads, runs, and messages as described in the [Azure AI Foundry documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/threads-runs-messages).\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Thread**: A conversation session storing messages (max 100,000 messages per thread)\n",
    "- **Messages**: Individual communications (text, files) within a thread\n",
    "- **Run**: Invocation of the agent to process thread messages and generate responses\n",
    "- **Run Status**: Monitor run lifecycle (queued ‚Üí in_progress ‚Üí completed)\n",
    "\n",
    "This pattern is useful when you need:\n",
    "- Fine-grained control over thread lifecycle\n",
    "- Access to intermediate run states\n",
    "- Custom message handling or storage\n",
    "- Integration with external systems tracking conversation state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43d5ba",
   "metadata": {},
   "source": [
    "### Visual Workflow\n",
    "\n",
    "![Azure AI Agent Run Workflow](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/media/run-thread-model.png?view=foundry-classic)\n",
    "\n",
    "*Source: [Microsoft Learn - Threads, runs, and messages](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/threads-runs-messages?view=foundry-classic)*\n",
    "\n",
    "The diagram above shows the complete lifecycle of an agent interaction using explicit thread management. Our demo below implements all these steps programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d1147",
   "metadata": {},
   "source": [
    "## 2. Azure OpenAI Chat Completion (`AzureOpenAIChatClient`)\n",
    "\n",
    "**Uses**: Azure OpenAI Chat Completion API  \n",
    "**Chat History**: Custom/client-managed only (you control storage)  \n",
    "**Best For**: Custom storage requirements, full control over conversation state\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME` ‚ö†Ô∏è Note: **CHAT**_DEPLOYMENT\n",
    "- `AZURE_OPENAI_API_VERSION` (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "async def demo_azure_openai_chat():\n",
    "    print(\"\\n=== Azure OpenAI Chat Completion Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_OPENAI_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_ENDPOINT\")\n",
    "        return\n",
    "    if not os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        print(\"üí° This is different from AZURE_OPENAI_DEPLOYMENT_NAME!\")\n",
    "        return\n",
    "    \n",
    "    agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "        name=\"ChatCompletionAgent\",\n",
    "        instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Azure OpenAI Chat Completion Agent created successfully\")\n",
    "    print(\"üìù Sending query...\")\n",
    "    \n",
    "    # Note: No thread needed for single-turn interactions\n",
    "    # For multi-turn conversations, pass thread=AgentThread()\n",
    "    result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "    print(f\"ü§ñ Response: {result.text}\")\n",
    "    print(f\"üíæ Chat History: Client-managed (you must implement storage)\")\n",
    "\n",
    "\n",
    "# Run the demoawait demo_azure_openai_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c65cec",
   "metadata": {},
   "source": [
    "## 3. Azure OpenAI Responses (`AzureOpenAIResponsesClient`)\n",
    "\n",
    "**Uses**: Azure OpenAI Responses API  \n",
    "**Chat History**: Both service-managed AND custom (most flexible!)  \n",
    "**Best For**: Scenarios requiring both convenience and customization\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME` ‚ö†Ô∏è Note: **RESPONSES**_DEPLOYMENT\n",
    "- `AZURE_OPENAI_API_VERSION` (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99782db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "async def demo_azure_openai_responses():\n",
    "    print(\"\\n=== Azure OpenAI Responses Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_OPENAI_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    # Check if endpoint is Azure OpenAI (not Azure AI Foundry)\n",
    "    endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', '')\n",
    "    if not endpoint.endswith('.openai.azure.com/') and not endpoint.endswith('.openai.azure.com'):\n",
    "        print(\"‚ö†Ô∏è  Azure OpenAI Responses API is NOT available on Azure AI Foundry endpoints\")\n",
    "        print(f\"   Your endpoint: {endpoint}\")\n",
    "        print(\"   Required: https://your-resource.openai.azure.com/\")\n",
    "        print(\"\\nüí° The Responses API only works with native Azure OpenAI Service endpoints.\")\n",
    "        print(\"üí° Since you're using Azure AI Foundry, this demo will be skipped.\")\n",
    "        print(\"üí° Use AzureAIClient (Demo #1) or AzureOpenAIChatClient (Demo #2) instead.\")\n",
    "        return\n",
    "    \n",
    "    if not os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME\")\n",
    "        print(\"üí° This is different from AZURE_OPENAI_DEPLOYMENT_NAME!\")\n",
    "        print(\"üí° Set: AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=your-deployment-name\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        agent = AzureOpenAIResponsesClient(credential=AzureCliCredential()).create_agent(\n",
    "            name=\"ResponsesAgent\",\n",
    "            instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Azure OpenAI Responses Agent created successfully\")\n",
    "        print(\"üìù Sending query...\")\n",
    "        \n",
    "        # Note: No thread needed for single-turn interactions\n",
    "        # For multi-turn conversations, pass thread=AgentThread()\n",
    "        result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "        print(f\"ü§ñ Response: {result.text}\")\n",
    "        print(f\"üíæ Chat History: Service-managed OR custom (your choice!)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"\\nüí° This typically means the Responses API is not available on your endpoint.\")\n",
    "\n",
    "\n",
    "# Run the demoawait demo_azure_openai_responses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444a126",
   "metadata": {},
   "source": [
    "## Comparison: Chat History Management\n",
    "\n",
    "Let's demonstrate multi-turn conversations with each agent type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demo_multi_turn_conversations():\n",
    "    print(\"\\n=== Multi-Turn Conversation Comparison ===\")\n",
    "    \n",
    "    # Import async credential and AgentThread for maintaining conversation state\n",
    "    from azure.identity.aio import AzureCliCredential as AsyncAzureCliCredential\n",
    "    from agent_framework import AgentThread\n",
    "    \n",
    "    # Azure AI Agent - Service-managed history\n",
    "    if os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"\\n1Ô∏è‚É£ Azure AI Agent (Service-managed history):\")\n",
    "        \n",
    "        # Create credential first\n",
    "        credential = AsyncAzureCliCredential()\n",
    "        \n",
    "        async with AzureAIClient(async_credential=credential).create_agent(\n",
    "            name=\"MultiTurnAgent\",\n",
    "            instructions=\"Remember the conversation context.\",\n",
    "        ) as agent:\n",
    "            # Create a thread to maintain conversation state\n",
    "            thread = AgentThread()\n",
    "            \n",
    "            # First turn\n",
    "            result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "            print(f\"   User: My favorite color is blue.\")\n",
    "            print(f\"   Agent: {result1.text}\")\n",
    "            \n",
    "            # Second turn (agent should remember because we're using the same thread)\n",
    "            result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "            print(f\"   User: What's my favorite color?\")\n",
    "            print(f\"   Agent: {result2.text}\")\n",
    "            print(f\"   ‚úÖ Service remembers context via AgentThread object\")\n",
    "    \n",
    "    # Azure OpenAI Chat - Client-managed history\n",
    "    if os.getenv('AZURE_OPENAI_ENDPOINT') and os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME'):\n",
    "        print(\"\\n2Ô∏è‚É£ Azure OpenAI Chat (Client-managed history):\")\n",
    "        agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "            instructions=\"Remember the conversation context.\",\n",
    "        )\n",
    "        \n",
    "        # Create a thread to maintain conversation state\n",
    "        thread = AgentThread()\n",
    "        \n",
    "        result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "        print(f\"   User: My favorite color is blue.\")\n",
    "        print(f\"   Agent: {result1.text}\")\n",
    "        \n",
    "        result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "        print(f\"   User: What's my favorite color?\")\n",
    "        print(f\"   Agent: {result2.text}\")\n",
    "        print(f\"   ‚úÖ AgentThread stores history client-side\")\n",
    "        \n",
    "    # Azure OpenAI Responses - Flexible history\n",
    "    if os.getenv('AZURE_OPENAI_ENDPOINT') and os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME'):\n",
    "        endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', '')\n",
    "        if endpoint.endswith('.openai.azure.com/') or endpoint.endswith('.openai.azure.com'):\n",
    "            print(\"\\n3Ô∏è‚É£ Azure OpenAI Responses (Flexible history):\")\n",
    "            agent = AzureOpenAIResponsesClient(credential=AzureCliCredential()).create_agent(\n",
    "                instructions=\"Remember the conversation context.\",\n",
    "            )\n",
    "            \n",
    "            # Create a thread to maintain conversation state\n",
    "            thread = AgentThread()\n",
    "            \n",
    "            result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "            print(f\"   User: My favorite color is blue.\")\n",
    "            print(f\"   Agent: {result1.text}\")\n",
    "            \n",
    "            result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "            print(f\"   User: What's my favorite color?\")\n",
    "            print(f\"   Agent: {result2.text}\")\n",
    "            print(f\"   ‚úÖ Can use service OR custom history via AgentThread\")\n",
    "        else:\n",
    "            print(\"\\n3Ô∏è‚É£ Azure OpenAI Responses (Skipped - requires .openai.azure.com endpoint)\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_multi_turn_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd8b40",
   "metadata": {},
   "source": [
    "## Summary: When to Use Each Agent Type\n",
    "\n",
    "### ‚úÖ Use Azure AI Agent when:\n",
    "- You want service-managed conversation threads\n",
    "- Building production apps with Azure AI Foundry/Projects\n",
    "- Need hosted agent infrastructure\n",
    "- Want automatic thread management\n",
    "\n",
    "### ‚úÖ Use Azure OpenAI Chat Completion when:\n",
    "- You need full control over chat history storage\n",
    "- Implementing custom persistence (database, Redis, etc.)\n",
    "- Want to manage conversation state manually\n",
    "- Building custom chat applications\n",
    "\n",
    "### ‚úÖ Use Azure OpenAI Responses when:\n",
    "- You want the flexibility of both options\n",
    "- Need structured response generation\n",
    "- Want to choose between service or custom history\n",
    "- Building applications that may evolve requirements\n",
    "\n",
    "---\n",
    "\n",
    "## Complete .env File Template\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL**: Each agent type uses **different deployment variable names**!\n",
    "\n",
    "Create a `.env` file in your project root with these variables:\n",
    "\n",
    "```bash\n",
    "# ========================================\n",
    "# Azure AI Agent (AzureAIClient)\n",
    "# ========================================\n",
    "AZURE_AI_PROJECT_ENDPOINT=\"https://your-ai-services.services.ai.azure.com/api/projects/your-project\"\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=\"gpt-4o\"\n",
    "\n",
    "# ========================================\n",
    "# Azure OpenAI Chat Completion (AzureOpenAIChatClient)\n",
    "# ========================================\n",
    "AZURE_OPENAI_ENDPOINT=\"https://your-resource.openai.azure.com/\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"gpt-4o\"        # Note: CHAT_DEPLOYMENT\n",
    "AZURE_OPENAI_API_VERSION=\"2024-10-21\"\n",
    "\n",
    "# ========================================\n",
    "# Azure OpenAI Responses (AzureOpenAIResponsesClient)\n",
    "# ========================================\n",
    "# Uses same AZURE_OPENAI_ENDPOINT as above\n",
    "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=\"gpt-4o\"   # Note: RESPONSES_DEPLOYMENT\n",
    "\n",
    "# Authentication: Run 'az login' in terminal\n",
    "```\n",
    "\n",
    "**Important**: \n",
    "- Don't commit your `.env` file to git! Add it to `.gitignore`.\n",
    "- See `AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md` for detailed explanation of variable naming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b6420",
   "metadata": {},
   "source": [
    "## üéì Key Learnings from This Demo\n",
    "\n",
    "### 1. Conversation State Management\n",
    "**Critical Discovery**: Without passing an `AgentThread` object, each `agent.run()` call is completely independent - the agent has NO memory of previous interactions.\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - Each call is a new conversation\n",
    "result1 = await agent.run(\"My favorite color is blue.\")\n",
    "result2 = await agent.run(\"What's my favorite color?\")  # Agent won't remember!\n",
    "\n",
    "# ‚úÖ Correct - Use AgentThread to maintain conversation state\n",
    "from agent_framework import AgentThread\n",
    "thread = AgentThread()\n",
    "result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "result2 = await agent.run(\"What's my favorite color?\", thread=thread)  # Agent remembers!\n",
    "```\n",
    "\n",
    "### 2. Environment Variable Naming Confusion\n",
    "Each agent type uses **different** deployment variable names. This is intentional to allow using different models for different agent types:\n",
    "\n",
    "| Agent Type | Deployment Variable Name |\n",
    "|------------|-------------------------|\n",
    "| Azure AI Agent | `AZURE_AI_MODEL_DEPLOYMENT_NAME` |\n",
    "| Azure OpenAI Chat | `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME` |\n",
    "| Azure OpenAI Responses | `AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME` |\n",
    "\n",
    "**Why?** This allows flexibility:\n",
    "```bash\n",
    "# You can use different models for different purposes\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=\"gpt-4o\"              # Production agent\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"gpt-4o-mini\"      # Cost-effective chat\n",
    "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=\"gpt-4o\"      # Advanced responses\n",
    "```\n",
    "\n",
    "### 3. Azure OpenAI Responses API Endpoint Requirements\n",
    "The Responses API has strict endpoint requirements:\n",
    "- ‚úÖ **Works with**: `https://your-resource.openai.azure.com/` (Native Azure OpenAI)\n",
    "- ‚ùå **Does NOT work with**: `https://your-resource.services.ai.azure.com/` (Azure AI Foundry)\n",
    "\n",
    "**Why?** The Responses API is a preview feature only available on native Azure OpenAI Service endpoints. The SDK checks for `.openai.azure.com` suffix before allowing the API call.\n",
    "\n",
    "### 4. Credential Initialization Pattern for Azure AI Agent\n",
    "Azure AI Agent requires creating the credential before passing it to the client:\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - Using async context manager for credential\n",
    "async with AzureCliCredential() as credential:\n",
    "    async with AzureAIClient(async_credential=credential).create_agent(...) as agent:\n",
    "\n",
    "# ‚úÖ Correct - Create credential first, then use it\n",
    "credential = AzureCliCredential()\n",
    "async with AzureAIClient(async_credential=credential).create_agent(...) as agent:\n",
    "```\n",
    "\n",
    "**Why?** The `AzureAIClient` needs an initialized credential at construction time, not one that's being set up in a context manager.\n",
    "\n",
    "### 5. Chat History Storage Differences\n",
    "\n",
    "| Agent Type | History Storage | When to Use |\n",
    "|------------|----------------|-------------|\n",
    "| **Azure AI Agent** | Service-managed (server-side) | Production apps, want Azure to handle persistence |\n",
    "| **Azure OpenAI Chat** | Client-managed (you store it) | Custom storage (DB, Redis), full control |\n",
    "| **Azure OpenAI Responses** | Both options available | Most flexible, can choose per use case |\n",
    "\n",
    "**Important**: Even though storage differs, all three use `AgentThread()` locally to maintain conversation state during execution.\n",
    "\n",
    "### 6. Authentication Pattern\n",
    "All demos use Azure CLI authentication:\n",
    "1. Run `az login` in terminal\n",
    "2. Use `AzureCliCredential()` in code\n",
    "3. Azure handles authentication automatically\n",
    "\n",
    "This is the recommended approach for development and testing. Production apps should use Managed Identity or Service Principal authentication.\n",
    "\n",
    "---\n",
    "\n",
    "üí° **See Also**: [AGENT_ENV_VARS_EXPLAINED.md](../docs/AGENT_ENV_VARS_EXPLAINED.md) for detailed explanation of environment variable naming patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19e0cd",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Microsoft Learn - Agent Types](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/?pivots=programming-language-python)\n",
    "- [MAF GitHub - Azure AI Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_ai)\n",
    "- [MAF GitHub - Azure OpenAI Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_openai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
