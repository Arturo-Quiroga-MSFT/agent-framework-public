{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d3e8bd",
   "metadata": {},
   "source": [
    "# Three Agent Types Demo - Microsoft Agent Framework (MAF)\n",
    "\n",
    "This notebook demonstrates the **three types of agents** available in Microsoft Agent Framework and their different chat history management approaches.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Azure AI Agent** (`AzureAIClient`) - Service-managed threads stored server-side\n",
    "2. **Azure OpenAI Chat Completion** (`AzureOpenAIChatClient`) - Client-managed history with full control\n",
    "3. **Azure OpenAI Responses** (`AzureOpenAIResponsesClient`) - Flexible history (both service and custom)\n",
    "\n",
    "Each demo shows:\n",
    "- How to create and configure each agent type\n",
    "- Environment variables required for each\n",
    "- Multi-turn conversations demonstrating memory/context handling\n",
    "- When to use each agent type based on your requirements\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+ with packages: `agent-framework`, `agent-framework-azure-ai`, `azure-identity`\n",
    "- Azure CLI authentication: Run `az login` before executing cells\n",
    "- Azure AI Foundry project (for Azure AI Agent)\n",
    "- Azure OpenAI resource (for Chat and Responses agents)\n",
    "\n",
    "**Note**: Each agent type uses different environment variable names - see setup cell below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1a36f",
   "metadata": {},
   "source": [
    "## Setup: Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1387a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded .env file\n",
      "\n",
      "=== Azure AI Agent Variables ===\n",
      "AZURE_AI_PROJECT_ENDPOINT: ‚úÖ Set\n",
      "AZURE_AI_MODEL_DEPLOYMENT_NAME: ‚úÖ Set\n",
      "\n",
      "=== Azure OpenAI Chat Completion Variables ===\n",
      "AZURE_OPENAI_ENDPOINT: ‚úÖ Set\n",
      "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME: ‚úÖ Set\n",
      "\n",
      "=== Azure OpenAI Responses Variables ===\n",
      "AZURE_OPENAI_ENDPOINT: ‚úÖ Set\n",
      "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME: ‚úÖ Set\n",
      "\n",
      "‚ö†Ô∏è  Note: Each agent type uses DIFFERENT deployment variable names!\n",
      "See: AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md for details\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "env_path = Path.cwd() / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"‚úÖ Loaded .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using system environment variables\")\n",
    "\n",
    "# Verify required variables\n",
    "print(\"\\n=== Azure AI Agent Variables ===\")\n",
    "print(f\"AZURE_AI_PROJECT_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_AI_PROJECT_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_AI_MODEL_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_AI_MODEL_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n=== Azure OpenAI Chat Completion Variables ===\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n=== Azure OpenAI Responses Variables ===\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_ENDPOINT') else '‚ùå Missing'}\")\n",
    "print(f\"AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME: {'‚úÖ Set' if os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME') else '‚ùå Missing'}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Note: Each agent type uses DIFFERENT deployment variable names!\")\n",
    "print(\"See: AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md for details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0bc8a",
   "metadata": {},
   "source": [
    "## 1. Azure AI Agent (`AzureAIClient`)\n",
    "\n",
    "**Uses**: Azure AI Agents Service (azure-ai-projects SDK backend)  \n",
    "**Chat History**: Service-managed only (threads stored server-side)  \n",
    "**Best For**: Production scenarios with hosted infrastructure\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_AI_PROJECT_ENDPOINT`\n",
    "- `AZURE_AI_MODEL_DEPLOYMENT_NAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56049c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Azure AI Agent Demo ===\n",
      "‚úÖ Azure AI Agent created successfully\n",
      "üìù Sending query...\n",
      "ü§ñ Response: I am an AI language agent designed to assist with information, tasks, and problem-solving through natural language conversation.\n",
      "üíæ Chat History: Service-managed (thread ID: N/A)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agent_framework.azure import AzureAIClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "async def demo_azure_ai_agent():\n",
    "    print(\"\\n=== Azure AI Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_AI_PROJECT_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIClient(credential=credential).create_agent(\n",
    "            name=\"AzureAIAgent\",\n",
    "            instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "        ) as agent,\n",
    "    ):\n",
    "        print(\"‚úÖ Azure AI Agent created successfully\")\n",
    "        print(\"üìù Sending query...\")\n",
    "        \n",
    "        result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "        print(f\"ü§ñ Response: {result.text}\")\n",
    "        print(f\"üíæ Chat History: Service-managed (thread ID: {result.thread_id if hasattr(result, 'thread_id') else 'N/A'})\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_azure_ai_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d1147",
   "metadata": {},
   "source": [
    "## 2. Azure OpenAI Chat Completion (`AzureOpenAIChatClient`)\n",
    "\n",
    "**Uses**: Azure OpenAI Chat Completion API  \n",
    "**Chat History**: Custom/client-managed only (you control storage)  \n",
    "**Best For**: Custom storage requirements, full control over conversation state\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME` ‚ö†Ô∏è Note: **CHAT**_DEPLOYMENT\n",
    "- `AZURE_OPENAI_API_VERSION` (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b54d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Azure OpenAI Chat Completion Agent Demo ===\n",
      "‚úÖ Azure OpenAI Chat Completion Agent created successfully\n",
      "üìù Sending query...\n",
      "ü§ñ Response: I am an AI language model designed to assist with information, tasks, and problem-solving.\n",
      "üíæ Chat History: Client-managed (you must implement storage)\n"
     ]
    }
   ],
   "source": [
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "async def demo_azure_openai_chat():\n",
    "    print(\"\\n=== Azure OpenAI Chat Completion Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_OPENAI_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_ENDPOINT\")\n",
    "        return\n",
    "    if not os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        print(\"üí° This is different from AZURE_OPENAI_DEPLOYMENT_NAME!\")\n",
    "        return\n",
    "    \n",
    "    agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "        name=\"ChatCompletionAgent\",\n",
    "        instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Azure OpenAI Chat Completion Agent created successfully\")\n",
    "    print(\"üìù Sending query...\")\n",
    "    \n",
    "    result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "    print(f\"ü§ñ Response: {result.text}\")\n",
    "    print(f\"üíæ Chat History: Client-managed (you must implement storage)\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_azure_openai_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c65cec",
   "metadata": {},
   "source": [
    "## 3. Azure OpenAI Responses (`AzureOpenAIResponsesClient`)\n",
    "\n",
    "**Uses**: Azure OpenAI Responses API  \n",
    "**Chat History**: Both service-managed AND custom (most flexible!)  \n",
    "**Best For**: Scenarios requiring both convenience and customization\n",
    "\n",
    "**Environment Variables Needed**:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME` ‚ö†Ô∏è Note: **RESPONSES**_DEPLOYMENT\n",
    "- `AZURE_OPENAI_API_VERSION` (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99782db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Azure OpenAI Responses Agent Demo ===\n",
      "‚úÖ Azure OpenAI Responses Agent created successfully\n",
      "üìù Sending query...\n",
      "ü§ñ Response: I am an AI language agent designed to assist with information, tasks, and conversations.\n",
      "üíæ Chat History: Service-managed OR custom (your choice!)\n"
     ]
    }
   ],
   "source": [
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "async def demo_azure_openai_responses():\n",
    "    print(\"\\n=== Azure OpenAI Responses Agent Demo ===\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    if not os.getenv('AZURE_OPENAI_ENDPOINT'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_ENDPOINT\")\n",
    "        return\n",
    "    \n",
    "    # Check if endpoint is Azure OpenAI (not Azure AI Foundry)\n",
    "    endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', '')\n",
    "    if not endpoint.endswith('.openai.azure.com/') and not endpoint.endswith('.openai.azure.com'):\n",
    "        print(\"‚ö†Ô∏è  Azure OpenAI Responses API is NOT available on Azure AI Foundry endpoints\")\n",
    "        print(f\"   Your endpoint: {endpoint}\")\n",
    "        print(\"   Required: https://your-resource.openai.azure.com/\")\n",
    "        print(\"\\nüí° The Responses API only works with native Azure OpenAI Service endpoints.\")\n",
    "        print(\"üí° Since you're using Azure AI Foundry, this demo will be skipped.\")\n",
    "        print(\"üí° Use AzureAIClient (Demo #1) or AzureOpenAIChatClient (Demo #2) instead.\")\n",
    "        return\n",
    "    \n",
    "    if not os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME'):\n",
    "        print(\"‚ùå Missing AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME\")\n",
    "        print(\"üí° This is different from AZURE_OPENAI_DEPLOYMENT_NAME!\")\n",
    "        print(\"üí° Set: AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=your-deployment-name\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        agent = AzureOpenAIResponsesClient(credential=AzureCliCredential()).create_agent(\n",
    "            name=\"ResponsesAgent\",\n",
    "            instructions=\"You are a helpful assistant. Keep responses concise.\",\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Azure OpenAI Responses Agent created successfully\")\n",
    "        print(\"üìù Sending query...\")\n",
    "        \n",
    "        result = await agent.run(\"What type of agent are you? Answer in one sentence.\")\n",
    "        print(f\"ü§ñ Response: {result.text}\")\n",
    "        print(f\"üíæ Chat History: Service-managed OR custom (your choice!)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"\\nüí° This typically means the Responses API is not available on your endpoint.\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_azure_openai_responses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444a126",
   "metadata": {},
   "source": [
    "## Comparison: Chat History Management\n",
    "\n",
    "Let's demonstrate multi-turn conversations with each agent type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f520fe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-Turn Conversation Comparison ===\n",
      "\n",
      "1Ô∏è‚É£ Azure AI Agent (Service-managed history):\n",
      "   User: My favorite color is blue.\n",
      "   Agent: Got it! Your favorite color is blue. I‚Äôll keep that in mind for future conversations and recommendations.\n",
      "   User: What's my favorite color?\n",
      "   Agent: Your favorite color is blue.\n",
      "   ‚úÖ Service remembers context via AgentThread object\n",
      "\n",
      "2Ô∏è‚É£ Azure OpenAI Chat (Client-managed history):\n",
      "   User: My favorite color is blue.\n",
      "   Agent: Got it! Your favorite color is blue. I'll remember that for our future conversations. If you ever want recommendations or ideas themed around blue, just let me know!\n",
      "   User: What's my favorite color?\n",
      "   Agent: Your favorite color is blue!\n",
      "   ‚úÖ AgentThread stores history client-side\n",
      "\n",
      "3Ô∏è‚É£ Azure OpenAI Responses (Flexible history):\n",
      "   User: My favorite color is blue.\n",
      "   Agent: Got it! Your favorite color is blue. If you have any questions or would like recommendations or ideas related to the color blue, just let me know!\n",
      "   User: What's my favorite color?\n",
      "   Agent: Your favorite color is blue!\n",
      "   ‚úÖ Can use service OR custom history via AgentThread\n"
     ]
    }
   ],
   "source": [
    "async def demo_multi_turn_conversations():\n",
    "    print(\"\\n=== Multi-Turn Conversation Comparison ===\")\n",
    "    \n",
    "    # Import async credential and AgentThread for maintaining conversation state\n",
    "    from azure.identity.aio import AzureCliCredential as AsyncAzureCliCredential\n",
    "    from agent_framework import AgentThread\n",
    "    \n",
    "    # Azure AI Agent - Service-managed history\n",
    "    if os.getenv('AZURE_AI_PROJECT_ENDPOINT'):\n",
    "        print(\"\\n1Ô∏è‚É£ Azure AI Agent (Service-managed history):\")\n",
    "        async with (\n",
    "            AsyncAzureCliCredential() as credential,\n",
    "            AzureAIClient(credential=credential).create_agent(\n",
    "                name=\"MultiTurnAgent\",\n",
    "                instructions=\"Remember the conversation context.\",\n",
    "            ) as agent,\n",
    "        ):\n",
    "            # Create a thread to maintain conversation state\n",
    "            thread = AgentThread()\n",
    "            \n",
    "            # First turn\n",
    "            result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "            print(f\"   User: My favorite color is blue.\")\n",
    "            print(f\"   Agent: {result1.text}\")\n",
    "            \n",
    "            # Second turn (agent should remember because we're using the same thread)\n",
    "            result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "            print(f\"   User: What's my favorite color?\")\n",
    "            print(f\"   Agent: {result2.text}\")\n",
    "            print(f\"   ‚úÖ Service remembers context via AgentThread object\")\n",
    "    \n",
    "    # Azure OpenAI Chat - Client-managed history\n",
    "    if os.getenv('AZURE_OPENAI_ENDPOINT') and os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME'):\n",
    "        print(\"\\n2Ô∏è‚É£ Azure OpenAI Chat (Client-managed history):\")\n",
    "        agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "            instructions=\"Remember the conversation context.\",\n",
    "        )\n",
    "        \n",
    "        # Create a thread to maintain conversation state\n",
    "        thread = AgentThread()\n",
    "        \n",
    "        result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "        print(f\"   User: My favorite color is blue.\")\n",
    "        print(f\"   Agent: {result1.text}\")\n",
    "        \n",
    "        result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "        print(f\"   User: What's my favorite color?\")\n",
    "        print(f\"   Agent: {result2.text}\")\n",
    "        print(f\"   ‚úÖ AgentThread stores history client-side\")\n",
    "        \n",
    "    # Azure OpenAI Responses - Flexible history\n",
    "    if os.getenv('AZURE_OPENAI_ENDPOINT') and os.getenv('AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME'):\n",
    "        endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', '')\n",
    "        if endpoint.endswith('.openai.azure.com/') or endpoint.endswith('.openai.azure.com'):\n",
    "            print(\"\\n3Ô∏è‚É£ Azure OpenAI Responses (Flexible history):\")\n",
    "            agent = AzureOpenAIResponsesClient(credential=AzureCliCredential()).create_agent(\n",
    "                instructions=\"Remember the conversation context.\",\n",
    "            )\n",
    "            \n",
    "            # Create a thread to maintain conversation state\n",
    "            thread = AgentThread()\n",
    "            \n",
    "            result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "            print(f\"   User: My favorite color is blue.\")\n",
    "            print(f\"   Agent: {result1.text}\")\n",
    "            \n",
    "            result2 = await agent.run(\"What's my favorite color?\", thread=thread)\n",
    "            print(f\"   User: What's my favorite color?\")\n",
    "            print(f\"   Agent: {result2.text}\")\n",
    "            print(f\"   ‚úÖ Can use service OR custom history via AgentThread\")\n",
    "        else:\n",
    "            print(\"\\n3Ô∏è‚É£ Azure OpenAI Responses (Skipped - requires .openai.azure.com endpoint)\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_multi_turn_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd8b40",
   "metadata": {},
   "source": [
    "## Summary: When to Use Each Agent Type\n",
    "\n",
    "### ‚úÖ Use Azure AI Agent when:\n",
    "- You want service-managed conversation threads\n",
    "- Building production apps with Azure AI Foundry/Projects\n",
    "- Need hosted agent infrastructure\n",
    "- Want automatic thread management\n",
    "\n",
    "### ‚úÖ Use Azure OpenAI Chat Completion when:\n",
    "- You need full control over chat history storage\n",
    "- Implementing custom persistence (database, Redis, etc.)\n",
    "- Want to manage conversation state manually\n",
    "- Building custom chat applications\n",
    "\n",
    "### ‚úÖ Use Azure OpenAI Responses when:\n",
    "- You want the flexibility of both options\n",
    "- Need structured response generation\n",
    "- Want to choose between service or custom history\n",
    "- Building applications that may evolve requirements\n",
    "\n",
    "---\n",
    "\n",
    "## Complete .env File Template\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL**: Each agent type uses **different deployment variable names**!\n",
    "\n",
    "Create a `.env` file in your project root with these variables:\n",
    "\n",
    "```bash\n",
    "# ========================================\n",
    "# Azure AI Agent (AzureAIClient)\n",
    "# ========================================\n",
    "AZURE_AI_PROJECT_ENDPOINT=\"https://your-ai-services.services.ai.azure.com/api/projects/your-project\"\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=\"gpt-4o\"\n",
    "\n",
    "# ========================================\n",
    "# Azure OpenAI Chat Completion (AzureOpenAIChatClient)\n",
    "# ========================================\n",
    "AZURE_OPENAI_ENDPOINT=\"https://your-resource.openai.azure.com/\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"gpt-4o\"        # Note: CHAT_DEPLOYMENT\n",
    "AZURE_OPENAI_API_VERSION=\"2024-10-21\"\n",
    "\n",
    "# ========================================\n",
    "# Azure OpenAI Responses (AzureOpenAIResponsesClient)\n",
    "# ========================================\n",
    "# Uses same AZURE_OPENAI_ENDPOINT as above\n",
    "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=\"gpt-4o\"   # Note: RESPONSES_DEPLOYMENT\n",
    "\n",
    "# Authentication: Run 'az login' in terminal\n",
    "```\n",
    "\n",
    "**Important**: \n",
    "- Don't commit your `.env` file to git! Add it to `.gitignore`.\n",
    "- See `AQ-CODE/docs/AGENT_ENV_VARS_EXPLAINED.md` for detailed explanation of variable naming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b6420",
   "metadata": {},
   "source": [
    "## üéì Key Learnings from This Demo\n",
    "\n",
    "### 1. Conversation State Management\n",
    "**Critical Discovery**: Without passing an `AgentThread` object, each `agent.run()` call is completely independent - the agent has NO memory of previous interactions.\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - Each call is a new conversation\n",
    "result1 = await agent.run(\"My favorite color is blue.\")\n",
    "result2 = await agent.run(\"What's my favorite color?\")  # Agent won't remember!\n",
    "\n",
    "# ‚úÖ Correct - Use AgentThread to maintain conversation state\n",
    "from agent_framework import AgentThread\n",
    "thread = AgentThread()\n",
    "result1 = await agent.run(\"My favorite color is blue.\", thread=thread)\n",
    "result2 = await agent.run(\"What's my favorite color?\", thread=thread)  # Agent remembers!\n",
    "```\n",
    "\n",
    "### 2. Environment Variable Naming Confusion\n",
    "Each agent type uses **different** deployment variable names. This is intentional to allow using different models for different agent types:\n",
    "\n",
    "| Agent Type | Deployment Variable Name |\n",
    "|------------|-------------------------|\n",
    "| Azure AI Agent | `AZURE_AI_MODEL_DEPLOYMENT_NAME` |\n",
    "| Azure OpenAI Chat | `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME` |\n",
    "| Azure OpenAI Responses | `AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME` |\n",
    "\n",
    "**Why?** This allows flexibility:\n",
    "```bash\n",
    "# You can use different models for different purposes\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=\"gpt-4o\"              # Production agent\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"gpt-4o-mini\"      # Cost-effective chat\n",
    "AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=\"gpt-4o\"      # Advanced responses\n",
    "```\n",
    "\n",
    "### 3. Azure OpenAI Responses API Endpoint Requirements\n",
    "The Responses API has strict endpoint requirements:\n",
    "- ‚úÖ **Works with**: `https://your-resource.openai.azure.com/` (Native Azure OpenAI)\n",
    "- ‚ùå **Does NOT work with**: `https://your-resource.services.ai.azure.com/` (Azure AI Foundry)\n",
    "\n",
    "**Why?** The Responses API is a preview feature only available on native Azure OpenAI Service endpoints. The SDK checks for `.openai.azure.com` suffix before allowing the API call.\n",
    "\n",
    "### 4. Async Context Manager Requirements\n",
    "Azure AI Agent requires async credentials when using context managers:\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - Sync credential with async context manager\n",
    "from azure.identity import AzureCliCredential\n",
    "async with AzureCliCredential() as cred:  # TypeError!\n",
    "\n",
    "# ‚úÖ Correct - Async credential for async context\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "async with AzureCliCredential() as cred:  # Works!\n",
    "```\n",
    "\n",
    "### 5. Chat History Storage Differences\n",
    "\n",
    "| Agent Type | History Storage | When to Use |\n",
    "|------------|----------------|-------------|\n",
    "| **Azure AI Agent** | Service-managed (server-side) | Production apps, want Azure to handle persistence |\n",
    "| **Azure OpenAI Chat** | Client-managed (you store it) | Custom storage (DB, Redis), full control |\n",
    "| **Azure OpenAI Responses** | Both options available | Most flexible, can choose per use case |\n",
    "\n",
    "**Important**: Even though storage differs, all three use `AgentThread()` locally to maintain conversation state during execution.\n",
    "\n",
    "### 6. Authentication Pattern\n",
    "All demos use Azure CLI authentication:\n",
    "1. Run `az login` in terminal\n",
    "2. Use `AzureCliCredential()` in code\n",
    "3. Azure handles authentication automatically\n",
    "\n",
    "This is the recommended approach for development and testing. Production apps should use Managed Identity or Service Principal authentication.\n",
    "\n",
    "---\n",
    "\n",
    "üí° **See Also**: [AGENT_ENV_VARS_EXPLAINED.md](../docs/AGENT_ENV_VARS_EXPLAINED.md) for detailed explanation of environment variable naming patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19e0cd",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Microsoft Learn - Agent Types](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/?pivots=programming-language-python)\n",
    "- [MAF GitHub - Azure AI Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_ai)\n",
    "- [MAF GitHub - Azure OpenAI Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_openai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
